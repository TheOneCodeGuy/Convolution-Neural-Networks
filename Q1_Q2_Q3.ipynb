{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Q1_Q2_Q3(New).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dac20009ad164436be09016a88007758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7aa2ac8931c54e4b83b36134b248e8a2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4091e796ca1844e98f32dd9f06e903bf",
              "IPY_MODEL_fc776e31986c4742928c5e923101b29d"
            ]
          }
        },
        "7aa2ac8931c54e4b83b36134b248e8a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4091e796ca1844e98f32dd9f06e903bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ac3abf0701a94d9689aed802836cd793",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8afe1fc23b9a4f0cbc4cae9c3c15b8fe"
          }
        },
        "fc776e31986c4742928c5e923101b29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_49edc0dde2a14b63b546277ae677e61b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [05:02&lt;00:00, 1.83MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29a3af9a393648d2b9605f806ce3fc65"
          }
        },
        "ac3abf0701a94d9689aed802836cd793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8afe1fc23b9a4f0cbc4cae9c3c15b8fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49edc0dde2a14b63b546277ae677e61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29a3af9a393648d2b9605f806ce3fc65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7_qTq010ijWD"
      },
      "source": [
        "### Run this cell only once (the first ever time you run) to process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v8PCDpQkAHwN",
        "colab": {}
      },
      "source": [
        "# # from google.colab import drive\n",
        "# # drive.mount('/content/drive')\n",
        "\n",
        "# # For extracting\n",
        "# !pip install pyunpack\n",
        "# !pip install patool\n",
        "\n",
        "# from pyunpack import Archive\n",
        "# Archive('CUB_200_2011.tgz').extractall('Assignment3_Data')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fjjzGKEwFmsN",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Z5GNnFsDPna",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "881e914e-8a45-4a4a-a2f6-397a45ad6824"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import tarfile\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from io import StringIO\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
        "import pickle\n",
        "import torchvision.models as models\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J6JD3ycyPuYi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35c4e6b5-4953-4423-aed6-3983cac9795a"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DP8iACDGDSWD",
        "colab": {}
      },
      "source": [
        "class DatasetClass(Dataset):\n",
        "    \n",
        "    def __init__(self, directory, img_size):\n",
        "        \n",
        "        self.directory = directory\n",
        "        self.classes = ['026.Bronzed_Cowbird',\t'084.Red_legged_Kittiwake',\t'131.Vesper_Sparrow',\t'085.Horned_Lark',\t'015.Lazuli_Bunting',\t'041.Scissor_tailed_Flycatcher',\t'114.Black_throated_Sparrow']\n",
        "        print('Number of Classes =', len(self.classes))\n",
        "        self.files = []\n",
        "        for class_name in self.classes:\n",
        "            images = os.listdir(directory + '/' + class_name)\n",
        "            images = [class_name + '/' + image for image in images]\n",
        "            self.files.extend(images)\n",
        "        \n",
        "        self.img_size = img_size\n",
        "        self.size = len(self.files)\n",
        "        \n",
        "    def __getitem__(self, idx):     \n",
        "        \n",
        "        image_name = self.files[idx]\n",
        "        y = self.classes.index(re.split('/', image_name)[0])\n",
        "        img = Image.open(self.directory + '/' + image_name).convert(mode='RGB').resize(self.img_size)\n",
        "        \n",
        "        trans = transforms.ToTensor()\n",
        "        # return trans(img), torch.Tensor(y, dtype=torch.long)\n",
        "        \n",
        "        return trans(img), y        # Multiplying by pixel value\n",
        "      \n",
        "    def __len__(self):\n",
        "        \n",
        "        return self.size"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TKVGwDDOKAsM",
        "colab": {}
      },
      "source": [
        "def train_test_loader(directory, img_size, train_fraction=0.7, cv_fraction=0.2, num_workers=0, batch_size=32):\n",
        "\n",
        "    dataset = DatasetClass(directory, img_size)\n",
        "    \n",
        "    N = dataset.size\n",
        "    train_size = int(N*train_fraction)\n",
        "    cv_size = int(N*cv_fraction)\n",
        "    test_size = N - train_size - cv_size\n",
        "\n",
        "    train_data, cv_data, test_data = torch.utils.data.random_split(dataset, [train_size, cv_size, test_size])\n",
        "\n",
        "    trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    cvloader = DataLoader(cv_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    testloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    \n",
        "    return trainloader, cvloader, testloader, train_size, cv_size, test_size"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fT66UkOpUDtv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3462be4-a3d4-4ebf-b120-84d98107ea4b"
      },
      "source": [
        "# trainloader, cvloader, testloader, train_size, cv_size, test_size = train_test_loader('D:/_SEM8/DL/Assignment 3/Assignment3_Data/CUB_200_2011/images/', (224, 224))\n",
        "trainloader, cvloader, testloader, train_size, cv_size, test_size = train_test_loader('/content/drive/My Drive/Assignment3_Data/CUB_200_2011/images', (224, 224), batch_size=32)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "  # trainloader, cvloader, testloader, train_size, cv_size, test_size = train_test_loader('Assignment3_Data/CUB_200_2011/images/', (224, 224))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Classes = 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "81_AjruYX-U6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c4fa8cc-6668-4fce-c74a-134b35260cfc"
      },
      "source": [
        "RGB_mean = torch.zeros(3)\n",
        "i = 0\n",
        "for X, y in trainloader:\n",
        "    i += 1\n",
        "    RGB_mean += (X.sum(0).sum(1).sum(1)/(X.shape[2]*X.shape[2]))/train_size\n",
        "    print(i, '/', len(trainloader), end=', ')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 / 9, 2 / 9, 3 / 9, 4 / 9, 5 / 9, 6 / 9, 7 / 9, 8 / 9, 9 / 9, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vc8N6oxxiwx0"
      },
      "source": [
        "### Question 1. a\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xzGC9uLa9xum",
        "colab": {}
      },
      "source": [
        "class VGGNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, RGB_mean, num_classes):\n",
        "        super(VGGNet, self).__init__()\n",
        "        \n",
        "        self.RGB_mean = RGB_mean.to(device)\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.c11 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n",
        "        self.c12 = nn.Conv2d(64, 64, 3, stride=1, padding=1)\n",
        "        self.p1 = nn.MaxPool2d(2, stride=2)\n",
        "\n",
        "        self.c21 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n",
        "        self.c22 = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n",
        "        self.p2 = nn.MaxPool2d(2, stride=2)\n",
        "\n",
        "        self.c31 = nn.Conv2d(128, 256, 3, stride=1, padding=1)\n",
        "        self.c32 = nn.Conv2d(256, 256, 3, stride=1, padding=1)\n",
        "        self.c33 = nn.Conv2d(256, 256, 3, stride=1, padding=1)\n",
        "        self.p3 = nn.MaxPool2d(2, stride=2)\n",
        "\n",
        "        self.c41 = nn.Conv2d(256, 512, 3, stride=1, padding=1)\n",
        "        self.c42 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
        "        self.c43 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
        "        self.p4 = nn.MaxPool2d(2, stride=2)\n",
        "\n",
        "        self.c51 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
        "        self.c52 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
        "        self.c53 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
        "        self.p5 = nn.MaxPool2d(2, stride=2)\n",
        "\n",
        "        self.flat = nn.Flatten(1, -1)\n",
        "        self.fc1 = nn.Linear(7*7*512, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.out = nn.Linear(4096, self.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x - self.RGB_mean[None, :, None, None]\n",
        "        x = self.p1(F.relu(self.c12(F.relu(self.c11(x)))))\n",
        "        x = self.p1(F.relu(self.c22(F.relu(self.c21(x)))))\n",
        "        x = self.p3(F.relu(self.c33(F.relu(self.c32(F.relu(self.c31(x)))))))\n",
        "        x = self.p4(F.relu(self.c43(F.relu(self.c42(F.relu(self.c41(x)))))))\n",
        "        x = self.p5(F.relu(self.c53(F.relu(self.c52(F.relu(self.c51(x)))))))\n",
        "        x = F.relu(self.fc2(F.relu(self.fc1(self.flat(x)))))\n",
        "        Z = self.out(x)\n",
        "\n",
        "\n",
        "        return Z"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EwuOkncsWXVy",
        "colab": {}
      },
      "source": [
        "VGG_model = VGGNet(RGB_mean, 7)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(VGG_model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZHF1Sn-Dhl0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "dac20009ad164436be09016a88007758",
            "7aa2ac8931c54e4b83b36134b248e8a2",
            "4091e796ca1844e98f32dd9f06e903bf",
            "fc776e31986c4742928c5e923101b29d",
            "ac3abf0701a94d9689aed802836cd793",
            "8afe1fc23b9a4f0cbc4cae9c3c15b8fe",
            "49edc0dde2a14b63b546277ae677e61b",
            "29a3af9a393648d2b9605f806ce3fc65"
          ]
        },
        "outputId": "346d6842-46f0-4793-8fc8-bd943ad237ca"
      },
      "source": [
        "# vgg16 = models.vgg16(pretrained=True)\n",
        "# pickle.dump(vgg16, open('/content/drive/My Drive/vgg_init.sav', 'wb'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dac20009ad164436be09016a88007758",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
            "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bms2NosWGTC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "54833055-e6d1-478c-97ff-2c3d0170a859"
      },
      "source": [
        "vgg16 = pickle.load(open('/content/drive/My Drive/vgg_init.sav', 'rb'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5db5f6d24950>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvgg16\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vgg_init.sav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'vgg_init.sav'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX8N4KctEfc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = list(vgg16.parameters())\n",
        "\n",
        "with torch.no_grad():\n",
        "    \n",
        "    VGG_model.c11.weight = params[0]\n",
        "    VGG_model.c11.bias = params[1]\n",
        "    VGG_model.c12.weight = params[2]\n",
        "    VGG_model.c12.bias = params[3]\n",
        "    \n",
        "    VGG_model.c21.weight = params[4]\n",
        "    VGG_model.c21.bias = params[5]\n",
        "    VGG_model.c22.weight = params[6]\n",
        "    VGG_model.c22.bias = params[7]\n",
        "\n",
        "    VGG_model.c31.weight = params[8]\n",
        "    VGG_model.c31.bias = params[9]\n",
        "    VGG_model.c32.weight = params[10]\n",
        "    VGG_model.c32.bias = params[11]\n",
        "    VGG_model.c33.weight = params[12]\n",
        "    VGG_model.c33.bias = params[13]\n",
        "\n",
        "    VGG_model.c41.weight = params[14]\n",
        "    VGG_model.c41.bias = params[15]\n",
        "    VGG_model.c42.weight = params[16]\n",
        "    VGG_model.c42.bias = params[17]\n",
        "    VGG_model.c43.weight = params[18]\n",
        "    VGG_model.c43.bias = params[19]\n",
        "\n",
        "    VGG_model.c51.weight = params[20]\n",
        "    VGG_model.c51.bias = params[21]\n",
        "    VGG_model.c52.weight = params[22]\n",
        "    VGG_model.c52.bias = params[23]\n",
        "    VGG_model.c53.weight = params[24]\n",
        "    VGG_model.c53.bias = params[25]\n",
        "\n",
        "    VGG_model.fc1.weight = params[26]\n",
        "    VGG_model.fc1.bias = params[27]\n",
        "\n",
        "    VGG_model.fc2.weight = params[28]\n",
        "    VGG_model.fc2.bias = params[29]\n",
        "\n",
        "VGG_model = VGG_model.to(device)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VUTJaWtqSqQj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f669b383-7314-47f1-b8d4-bcd50d6e5494"
      },
      "source": [
        "old_loss = np.inf\n",
        "\n",
        "max_epoch = 100\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for data in trainloader:\n",
        "        \n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward\n",
        "        y_hat = VGG_model(X)\n",
        "        \n",
        "        # Calculate Loss (Cross Entropy)\n",
        "        loss = criterion(y_hat, y)\n",
        "        \n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update Parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()*len(X)/train_size\n",
        "    \n",
        "    print('Epoch', epoch+1, ': Loss =', running_loss, abs(running_loss-old_loss)/running_loss)\n",
        "    \n",
        "    if abs(running_loss-old_loss)/running_loss < 1e-2:\n",
        "        print('Converged')\n",
        "        break\n",
        "    \n",
        "    old_loss = running_loss\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 : Loss = 1.8065746237591997 inf\n",
            "Epoch 2 : Loss = 1.0674737531964371 0.6923831788365787\n",
            "Epoch 3 : Loss = 0.6118119842914753 0.7447741799838273\n",
            "Epoch 4 : Loss = 0.419215380626273 0.45942160656767644\n",
            "Epoch 5 : Loss = 0.32592544032306203 0.2862309251181516\n",
            "Epoch 6 : Loss = 0.27672390800735264 0.1778000775935923\n",
            "Epoch 7 : Loss = 0.24220228631321977 0.1425321875347162\n",
            "Epoch 8 : Loss = 0.21691716927061513 0.11656577083144662\n",
            "Epoch 9 : Loss = 0.1965590464113481 0.10357255608913898\n",
            "Epoch 10 : Loss = 0.1817337170710547 0.08157720856222271\n",
            "Epoch 11 : Loss = 0.1695176391547565 0.07206375677014862\n",
            "Epoch 12 : Loss = 0.15518886650480876 0.09233118955414081\n",
            "Epoch 13 : Loss = 0.14711869136797012 0.05485485944579052\n",
            "Epoch 14 : Loss = 0.13707295916844742 0.07328748325318941\n",
            "Epoch 15 : Loss = 0.1292872263008294 0.06022043391589163\n",
            "Epoch 16 : Loss = 0.12262478870589558 0.0543318986743624\n",
            "Epoch 17 : Loss = 0.11735344950745746 0.044918485315620274\n",
            "Epoch 18 : Loss = 0.11053066365810221 0.06172753897922625\n",
            "Epoch 19 : Loss = 0.10553663782126398 0.047320304492702144\n",
            "Epoch 20 : Loss = 0.10016128750524454 0.05366694508332848\n",
            "Epoch 21 : Loss = 0.09629247968412859 0.04017767362318359\n",
            "Epoch 22 : Loss = 0.09236249293911333 0.042549595836547605\n",
            "Epoch 23 : Loss = 0.08889150474129653 0.039047468123287084\n",
            "Epoch 24 : Loss = 0.08539684472495256 0.04092258944226373\n",
            "Epoch 25 : Loss = 0.08144498891635225 0.04852177968443264\n",
            "Epoch 26 : Loss = 0.07874344502176557 0.034308175033997385\n",
            "Epoch 27 : Loss = 0.07608346041382812 0.03496140414052466\n",
            "Epoch 28 : Loss = 0.07353737205266953 0.034623053422891036\n",
            "Epoch 29 : Loss = 0.07100574744910729 0.03565379838268383\n",
            "Epoch 30 : Loss = 0.06874793497942881 0.032841895110799636\n",
            "Epoch 31 : Loss = 0.0669527103157409 0.026813323242955295\n",
            "Epoch 32 : Loss = 0.06460327024243849 0.0363672003674985\n",
            "Epoch 33 : Loss = 0.06268707849734335 0.030567571356453358\n",
            "Epoch 34 : Loss = 0.0609046815008652 0.029265352885111718\n",
            "Epoch 35 : Loss = 0.05932818954155005 0.02657239284558082\n",
            "Epoch 36 : Loss = 0.05761839057406482 0.029674535342798063\n",
            "Epoch 37 : Loss = 0.05649926368056274 0.019807813776643826\n",
            "Epoch 38 : Loss = 0.054620966224408735 0.03438784748766748\n",
            "Epoch 39 : Loss = 0.05332375824036083 0.024327017203113203\n",
            "Epoch 40 : Loss = 0.051906043994613654 0.027313086042432568\n",
            "Epoch 41 : Loss = 0.050500435319823254 0.027833595213359427\n",
            "Epoch 42 : Loss = 0.04944724597374321 0.0212992518661058\n",
            "Epoch 43 : Loss = 0.04838600062898228 0.021932900652368963\n",
            "Epoch 44 : Loss = 0.047346001237838525 0.02196593933919381\n",
            "Epoch 45 : Loss = 0.04629705992984855 0.02265675854102578\n",
            "Epoch 46 : Loss = 0.04526666711483683 0.022762727646763046\n",
            "Epoch 47 : Loss = 0.0442814586703578 0.022248780281001315\n",
            "Epoch 48 : Loss = 0.043303935149301635 0.022573549440389116\n",
            "Epoch 49 : Loss = 0.04255579493758155 0.0175802193994359\n",
            "Epoch 50 : Loss = 0.041618364743031704 0.02252443603533946\n",
            "Epoch 51 : Loss = 0.040795458331444545 0.0201715201947584\n",
            "Epoch 52 : Loss = 0.04023637255906851 0.013895034189656957\n",
            "Epoch 53 : Loss = 0.03929957900624657 0.0238372414287961\n",
            "Epoch 54 : Loss = 0.03847897579757179 0.02132601483448421\n",
            "Epoch 55 : Loss = 0.03789160653741102 0.015501302632308625\n",
            "Epoch 56 : Loss = 0.03719561521080728 0.018711649818377384\n",
            "Epoch 57 : Loss = 0.036532615366609254 0.018148162608801588\n",
            "Epoch 58 : Loss = 0.035910452024861914 0.017325411033996395\n",
            "Epoch 59 : Loss = 0.0353341394782274 0.016310360324174013\n",
            "Epoch 60 : Loss = 0.03473517375930053 0.01724378070129829\n",
            "Epoch 61 : Loss = 0.03414643349495915 0.017241632700185187\n",
            "Epoch 62 : Loss = 0.033627232653494495 0.015439892030803128\n",
            "Epoch 63 : Loss = 0.03303043595563867 0.01806808419535696\n",
            "Epoch 64 : Loss = 0.032582915125200555 0.013734830929599316\n",
            "Epoch 65 : Loss = 0.03198536841088471 0.018681876870691293\n",
            "Epoch 66 : Loss = 0.03151408972328964 0.014954539119903056\n",
            "Epoch 67 : Loss = 0.03109858940495016 0.013360744853377213\n",
            "Epoch 68 : Loss = 0.03060422938979046 0.0161533234136788\n",
            "Epoch 69 : Loss = 0.03015257655691602 0.014978913394744218\n",
            "Epoch 70 : Loss = 0.029708140377175934 0.01496008077575723\n",
            "Epoch 71 : Loss = 0.029438183360606534 0.009170301484386086\n",
            "Epoch 72 : Loss = 0.028905417439154625 0.018431351928176486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-262686ceb8c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Update Parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuguuhIInaRW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "2e776905-a031-417f-89ff-e299b70d1e11"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    train_loss = 0.0\n",
        "    y_train = []\n",
        "    y_train_pred = []\n",
        "\n",
        "    for data in trainloader:\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        y_hat = VGG_model(X)\n",
        "        train_loss += criterion(y_hat, y)*len(X)/train_size\n",
        "        \n",
        "        y_train.extend(list(y.detach().cpu().numpy()))\n",
        "        y_train_pred.extend(list(torch.argmax(y_hat, axis=1).detach().cpu().numpy()))\n",
        "\n",
        "print('Train Loss =', train_loss.item())\n",
        "plt.imshow(confusion_matrix(y_train, y_train_pred), cmap='Reds')\n",
        "plt.show()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Loss = 0.028267305344343185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAKXUlEQVR4nO3df6jV9R3H8dcrMyxzC0qaeCWNRRBRGSKMIppjYStqsP1RULAfEINaxgat9s/oz/0TLRgboW6NfkhUQkTrB2Q0Yf1Qs5VaQ5yVUqhFlBtbWK/9cb+ym9P8eu75fs/Ze88HiPfce7rvT9Tzfs/5nnO/HycRgDqOG/UCAAwXUQPFEDVQDFEDxRA1UMzxXXzTWXbmjOjnxRmLzxvJXKBPO99+W/v2ve/Dfa2TqOfoOH1HJ3XxrY/qt+ufG8lcoE9LLr70iF/j4TdQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVBMq6htL7f9pu3ttm/relEABnfUqG3PkPRrSZdLOkfStbbP6XphAAbT5ki9VNL2JDuSfCJpjaSru10WgEG1iXq+pHem3N7VfO5zbN9ge4PtDf8UVygFRmVoJ8qS3JNkSZIls3TY390G0IM2Ue+WtGDK7YnmcwDGUJuoX5Z0lu1Ftk+QdI2kx7pdFoBBHfVyRkkO2L5J0lOSZkhanWRL5ysDMJBW1yhL8oSkJzpeC4Ah4B1lQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxnex6ecbi80a2++Tqr3x1JHMl6QfvbR/ZbOAgjtRAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0U02bXy9W299h+vY8FAZieNkfq30ta3vE6AAzJUaNO8rykD3pYC4AhGNpz6qlb2e7d9/6wvi2AY9TJVrZzTzt1WN8WwDHi7DdQDFEDxbR5SetBSX+WdLbtXbZ/2P2yAAyqzf7U1/axEADDwcNvoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqCYTrayHaVRbid799wzRzb75r07RjYb44UjNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8W0ue73AtvrbG+1vcX2ij4WBmAwbX5L64CknybZZHuOpI22n0myteO1ARhAm61s302yqfn4Y0nbJM3vemEABnNMz6ltL5S0WNKLh/kaW9kCY6B11LZPlvSIpFuSfHTo19nKFhgPraK2PVOTQd+f5NFulwRgOtqc/bakVZK2Jbmz+yUBmI42R+qLJF0vaZntzc2fb3W8LgADarOV7XpJ7mEtAIaAd5QBxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8WU28p2lEa5nezms88f2WxJuuDNV0c6H//BkRoohqiBYogaKIaogWKIGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFi2lzMf5btl2y/2mxle0cfCwMwmDa/pfUvScuS7G+231lv+49JXuh4bQAG0OZi/pG0v7k5s/mTLhcFYHBtN8ibYXuzpD2SnknCVrbAmGoVdZJPk1wgaULSUtvnHuY+bGULjIFjOvud5ENJ6yQt72Y5AKarzdnvubZPaT4+UdI3Jb3R9cIADKbN2e95ku61PUOTPwQeSvJ4t8sCMKg2Z7//ImlxD2sBMAS8owwohqiBYogaKIaogWKIGiiGqIFiiBoohqiBYogaKIaogWLYn7qIUe8P/ctTF41s9s/e/9vIZo8jjtRAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxraNu9tN6xTbX/AbG2LEcqVdI2tbVQgAMR9tdLyckXSFpZbfLATBdbY/Ud0m6VdJnR7oDW9kC46HNBnlXStqTZOMX3Y+tbIHx0OZIfZGkq2zvlLRG0jLb93W6KgADO2rUSW5PMpFkoaRrJD2b5LrOVwZgILxODRRzTNcoS/KcpOc6WQmAoeBIDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMWxli6EY5Xayd889c2Szb967Y2Szj4QjNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UEyr9343u3N8LOlTSQeSLOlyUQAGdyy/0PH1JPs6WwmAoeDhN1BM26gj6WnbG23fcLg7sJUtMB7aRn1xkgslXS7pRtuXHHoHtrIFxkOrqJPsbv7eI2mtpKVdLgrA4NpsOj/b9pyDH0u6TNLrXS8MwGDanP0+XdJa2wfv/0CSJztdFYCBHTXqJDsknd/DWgAMAS9pAcUQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFvZ4n/eKLeT/dHsiZHMfUv/OOLXOFIDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFtIra9im2H7b9hu1ttr/W9cIADKbtL3T8StKTSb5r+wRJJ3W4JgDTcNSobX9Z0iWSvidJST6R9Em3ywIwqDYPvxdJ2ivpd7Zfsb2y2VPrc9jKFhgPbaI+XtKFkn6TZLGkv0u67dA7sZUtMB7aRL1L0q4kLza3H9Zk5ADG0FGjTvKepHdsn9186huStna6KgADa3v2+8eS7m/OfO+Q9P3ulgRgOlpFnWSzpCUdrwXAEPCOMqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgGKIGinGS4X9Te6+ktwb8x0+TtG+Iy2E2syvOPiPJ3MN9oZOop8P2hiQjeZ85s5ldYTYPv4FiiBooZhyjvofZzGb24MbuOTWA6RnHIzWAaSBqoJixitr2cttv2t5u+78uQ9zh3NW299h+va+ZU2YvsL3O9lbbW2yv6HH2LNsv2X61mX1HX7OnrGFGcz35x3ueu9P2a7Y3297Q8+xOt7Eam+fUtmdI+qukb2ryssQvS7o2SedXLrV9iaT9kv6Q5Nyu5x0ye56keUk22Z4jaaOkb/f0721Js5Pstz1T0npJK5K80PXsKWv4iSavf/elJFf2OHenpCVJen/zie17Jf0pycqD21gl+XBY33+cjtRLJW1PsqPZ2meNpKv7GJzkeUkf9DHrMLPfTbKp+fhjSdskze9pdpLsb27ObP709lPe9oSkKySt7GvmqE3ZxmqVNLmN1TCDlsYr6vmS3plye5d6+p97XNheKGmxpBe/+J5DnTnD9mZJeyQ9M2XThj7cJelWSZ/1OPOgSHra9kbbN/Q4t9U2VtMxTlH/X7N9sqRHJN2S5KO+5ib5NMkFkiYkLbXdy9MP21dK2pNkYx/zDuPiJBdKulzSjc1TsD602sZqOsYp6t2SFky5PdF8rrzm+ewjku5P8ugo1tA8BFwnaXlPIy+SdFXz3HaNpGW27+tptpLsbv7eI2mtJp/+9aHzbazGKeqXJZ1le1Fz8uAaSY+NeE2da05WrZK0LcmdPc+ea/uU5uMTNXmS8o0+Zie5PclEkoWa/G/9bJLr+phte3ZzUlLNQ9/LJPXyykcf21i13Xanc0kO2L5J0lOSZkhanWRLH7NtPyjpUkmn2d4l6RdJVvUxW5NHrOslvdY8t5Wknyd5oofZ8yTd27zycJykh5L0+tLSiJwuae3kz1MdL+mBJE/2OL/TbazG5iUtAMMxTg+/AQwBUQPFEDVQDFEDxRA1UAxRA8UQNVDMvwHRCc4EGYSyuwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHtBQ8zvtwUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49609e11-760b-4cef-f07a-c85c31125928"
      },
      "source": [
        "acc_tr = accuracy_score(y_train, y_train_pred)\n",
        "prec_tr = precision_score(y_train, y_train_pred, average='weighted')\n",
        "f1_tr = f1_score(y_train, y_train_pred, average='weighted')\n",
        "\n",
        "print('Train Accuracy =', acc_tr, 'Train Precision =', prec_tr, 'Train F1 =', f1_tr)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy = 1.0 Train Precision = 1.0 Train F1 = 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ok3viz8oX4nv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c68e8230-6544-40a2-dca7-440333d08a9b"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    test_loss = 0.0\n",
        "    y_test = []\n",
        "    y_test_pred = []\n",
        "\n",
        "    for data in testloader:\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        y_hat = VGG_model(X)      \n",
        "        test_loss += criterion(y_hat, y)*len(X)/test_size\n",
        "        \n",
        "        y_test.extend(list(y.detach().cpu().numpy()))\n",
        "        y_test_pred.extend(list(torch.argmax(y_hat, axis=1).detach().cpu().numpy()))\n",
        "\n",
        "print('Test Loss =', test_loss.item())\n",
        "print(pd.DataFrame(confusion_matrix(y_test, y_test_pred)))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss = 0.38136518001556396\n",
            "   0  1  2  3  4  5  6\n",
            "0  7  0  0  0  0  0  0\n",
            "1  0  5  0  0  0  0  0\n",
            "2  0  0  6  0  0  0  2\n",
            "3  0  0  0  4  0  1  0\n",
            "4  0  0  0  0  5  0  0\n",
            "5  0  0  0  0  1  5  0\n",
            "6  0  0  0  0  1  0  5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbtJA8AXtybh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee758bcf-12a3-45a9-bddb-938e353c7dc2"
      },
      "source": [
        "acc = accuracy_score(y_test, y_test_pred)\n",
        "prec = precision_score(y_test, y_test_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "\n",
        "print('Test Accuracy =', acc, 'Test Precision =', prec, 'Test F1 =', f1)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy = 0.8809523809523809 Test Precision = 0.8945578231292517 Test F1 = 0.8831327402755973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r_MY7HHT7GYv"
      },
      "source": [
        "### Question 1. b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZEvZrYhn7JuX",
        "colab": {}
      },
      "source": [
        "class GoogLeNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_classes, RGB_mean):\n",
        "    \n",
        "        super(GoogLeNet, self).__init__()\n",
        "        self.RGB_mean = RGB_mean.to(device)\n",
        "        self.n_classes = n_classes\n",
        "        # Convolution\n",
        "        # 3x224x224\n",
        "        self.c1 = nn.Conv2d(3, 64, 7, stride=2, padding=3)\n",
        "        # 64x112x112\n",
        "        self.mp1 = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        # Deep Convolution\n",
        "        # 64x56x56\n",
        "        self.c21 = nn.Conv2d(64, 64, 1, stride=1, padding=0)\n",
        "        # 64x56x56\n",
        "        self.c22 = nn.Conv2d(64, 192, 3, stride=1, padding=1)\n",
        "        # 192x56x56\n",
        "        self.mp2 = nn.MaxPool2d(3, stride=2)\n",
        "\n",
        "        # Inception 3a\n",
        "        # 192x28x28\n",
        "        # P1\n",
        "        self.c3a1 = nn.Conv2d(192, 64, 1, stride=1, padding=0)\n",
        "        # P2\n",
        "        self.c3a21 = nn.Conv2d(192, 96, 1, stride=1, padding=0)\n",
        "        self.c3a22 = nn.Conv2d(96, 128, 3, stride=1, padding=1)\n",
        "        # P3\n",
        "        self.c3a31 = nn.Conv2d(192, 16, 1, stride=1, padding=0)\n",
        "        self.c3a32 = nn.Conv2d(16, 32, 3, stride=1, padding=1)\n",
        "        # P4\n",
        "        self.mp3a4 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.c3a4 = nn.Conv2d(192, 32, 1, stride=1, padding=0)\n",
        "\n",
        "        # Inception 3b\n",
        "        # 256x28x28\n",
        "        # P1\n",
        "        self.c3b1 = nn.Conv2d(256, 128, 1, stride=1, padding=0)\n",
        "        # P2\n",
        "        self.c3b21 = nn.Conv2d(256, 128, 1, stride=1, padding=0)\n",
        "        self.c3b22 = nn.Conv2d(128, 192, 3, stride=1, padding=1)\n",
        "        # P3\n",
        "        self.c3b31 = nn.Conv2d(256, 32, 1, stride=1, padding=0)\n",
        "        self.c3b32 = nn.Conv2d(32, 96, 3, stride=1, padding=1)\n",
        "        # P4\n",
        "        self.mp3b4 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.c3b4 = nn.Conv2d(256, 64, 1, stride=1, padding=0)\n",
        "\n",
        "        # 480x28x28\n",
        "        # MP\n",
        "        self.mp3 = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        # Inception 4a\n",
        "        # 480x14x14\n",
        "        # P1\n",
        "        self.c4a1 = nn.Conv2d(480, 192, 1, stride=1, padding=0)\n",
        "        # P2\n",
        "        self.c4a21 = nn.Conv2d(480, 96, 1, stride=1, padding=0)\n",
        "        self.c4a22 = nn.Conv2d(96, 208, 3, stride=1, padding=1)\n",
        "        # P3\n",
        "        self.c4a31 = nn.Conv2d(480, 16, 1, stride=1, padding=0)\n",
        "        self.c4a32 = nn.Conv2d(16, 48, 3, stride=1, padding=1)\n",
        "        # P4\n",
        "        self.mp4a4 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.c4a4 = nn.Conv2d(480, 64, 1, stride=1, padding=0)\n",
        "\n",
        "        # Auxiliary 1\n",
        "        # 512x14x14\n",
        "        self.apa1 = nn.AvgPool2d(5, stride=3, padding=0)\n",
        "        # 512x4x4\n",
        "        self.ca1 = nn.Conv2d(512, 128, 1, stride=1)\n",
        "        # 128x4x4\n",
        "        self.flat1 = nn.Flatten(1, -1)\n",
        "        # (128x4x4)x1\n",
        "        self.fca1 = nn.Linear(2048, 1024)\n",
        "        self.a1drop = nn.Dropout(0.7)\n",
        "        self.a1out = nn.Linear(1024, self.n_classes)\n",
        "\n",
        "        # Inception 4b\n",
        "        # 512x14x14\n",
        "        # P1\n",
        "        self.c4b1 = nn.Conv2d(512, 160, 1, stride=1, padding=0)\n",
        "        # P2\n",
        "        self.c4b21 = nn.Conv2d(512, 112, 1, stride=1, padding=0)\n",
        "        self.c4b22 = nn.Conv2d(112, 224, 3, stride=1, padding=1)\n",
        "        # P3\n",
        "        self.c4b31 = nn.Conv2d(512, 24, 1, stride=1, padding=0)\n",
        "        self.c4b32 = nn.Conv2d(24, 64, 3, stride=1, padding=1)\n",
        "        # P4\n",
        "        self.mp4b4 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.c4b4 = nn.Conv2d(512, 64, 1, stride=1, padding=0)\n",
        "\n",
        "        # Inception 4c\n",
        "        # 512x14x14\n",
        "        # P1\n",
        "        self.c4c1 = nn.Conv2d(512, 128, 1, stride=1, padding=0)\n",
        "        # P2\n",
        "        self.c4c21 = nn.Conv2d(512, 128, 1, stride=1, padding=0)\n",
        "        self.c4c22 = nn.Conv2d(128, 256, 3, stride=1, padding=1)\n",
        "        # P3\n",
        "        self.c4c31 = nn.Conv2d(512, 24, 1, stride=1, padding=0)\n",
        "        self.c4c32 = nn.Conv2d(24, 64, 3, stride=1, padding=1)\n",
        "        # P4\n",
        "        self.mp4c4 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.c4c4 = nn.Conv2d(512, 64, 1, stride=1, padding=0)\n",
        "\n",
        "        # Inception 4d\n",
        "        # 512x14x14\n",
        "        # P1\n",
        "        self.c4d1 = nn.Conv2d(512, 112, 1, stride=1, padding=0)\n",
        "        # P2\n",
        "        self.c4d21 = nn.Conv2d(512, 144, 1, stride=1, padding=0)\n",
        "        self.c4d22 = nn.Conv2d(144, 288, 3, stride=1, padding=1)\n",
        "        # P3\n",
        "        self.c4d31 = nn.Conv2d(512, 32, 1, stride=1, padding=0)\n",
        "        self.c4d32 = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
        "        # P4\n",
        "        self.mp4d4 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.c4d4 = nn.Conv2d(512, 64, 1, stride=1, padding=0)\n",
        "\n",
        "        # Auxiliary 2\n",
        "        # 528x14x14\n",
        "        self.apa2 = nn.AvgPool2d(5, stride=3, padding=0)\n",
        "        # 528x4x4\n",
        "        self.ca2 = nn.Conv2d(528, 128, 1, stride=1)\n",
        "        # 128x4x4\n",
        "        self.flat1 = nn.Flatten(1, -1)\n",
        "        # (128x4x4)x1\n",
        "        self.fca2 = nn.Linear(2048, 1024)\n",
        "        self.a2drop = nn.Dropout(0.7)\n",
        "        self.a2out = nn.Linear(1024, self.n_classes)\n",
        "\n",
        "        # Inception 4e\n",
        "        # 528x14x14\n",
        "        # P1\n",
        "        self.c4e1 = nn.Conv2d(528, 256, 1, stride=1, padding=0)\n",
        "        # P2\n",
        "        self.c4e21 = nn.Conv2d(528, 160, 1, stride=1, padding=0)\n",
        "        self.c4e22 = nn.Conv2d(160, 320, 3, stride=1, padding=1)\n",
        "        # P3\n",
        "        self.c4e31 = nn.Conv2d(528, 32, 1, stride=1, padding=0)\n",
        "        self.c4e32 = nn.Conv2d(32, 128, 3, stride=1, padding=1)\n",
        "        # P4\n",
        "        self.mp4e4 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.c4e4 = nn.Conv2d(528, 128, 1, stride=1, padding=0)\n",
        "\n",
        "        # 832x14x14\n",
        "        # MP\n",
        "        self.mp4 = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        # Inception 5a\n",
        "        # 832x7x7\n",
        "        # P1\n",
        "        self.c5a1 = nn.Conv2d(832, 256, 1, stride=1, padding=0)\n",
        "        # P2\n",
        "        self.c5a21 = nn.Conv2d(832, 160, 1, stride=1, padding=0)\n",
        "        self.c5a22 = nn.Conv2d(160, 320, 3, stride=1, padding=1)\n",
        "        # P3\n",
        "        self.c5a31 = nn.Conv2d(832, 32, 1, stride=1, padding=0)\n",
        "        self.c5a32 = nn.Conv2d(32, 128, 3, stride=1, padding=1)\n",
        "        # P4\n",
        "        self.mp5a4 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.c5a4 = nn.Conv2d(832, 128, 1, stride=1, padding=0)\n",
        "\n",
        "        # Inception 5b\n",
        "        # 832x7x7\n",
        "        # P1\n",
        "        self.c5b1 = nn.Conv2d(832, 384, 1, stride=1, padding=0)\n",
        "        # P2\n",
        "        self.c5b21 = nn.Conv2d(832, 192, 1, stride=1, padding=0)\n",
        "        self.c5b22 = nn.Conv2d(192, 384, 3, stride=1, padding=1)\n",
        "        # P3\n",
        "        self.c5b31 = nn.Conv2d(832, 48, 1, stride=1, padding=0)\n",
        "        self.c5b32 = nn.Conv2d(48, 128, 3, stride=1, padding=1)\n",
        "        # P4\n",
        "        self.mp5b4 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.c5b4 = nn.Conv2d(832, 128, 1, stride=1, padding=0)\n",
        "\n",
        "        # 1024x7x7\n",
        "        self.ap = nn.AvgPool2d(7, stride=1)\n",
        "        # 1024x1x1\n",
        "        self.drop = nn.Dropout(0.4)\n",
        "        self.flat = nn.Flatten(1, -1)\n",
        "        self.out = nn.Linear(1024, self.n_classes)\n",
        "\n",
        "    def forward(self, x, auxiliary=True):\n",
        "\n",
        "        x = x - self.RGB_mean[None, :, None, None]\n",
        "\n",
        "        # Layer 1\n",
        "        x = self.mp1(F.relu(self.c1(x)))\n",
        "\n",
        "        # Layer 2\n",
        "        x = self.mp2(F.relu(self.c22(F.relu(self.c21(x)))))\n",
        "\n",
        "        # Layer 3a\n",
        "        x1 = F.relu(self.c3a1(x))\n",
        "        x2 = F.relu(self.c3a22(F.relu(self.c3a21(x))))\n",
        "        x3 = F.relu(self.c3a32(F.relu(self.c3a31(x))))\n",
        "        x4 = F.relu(self.c3a4(self.mp3a4(x)))\n",
        "        x = torch.cat((x1, x2, x3, x4), 1)\n",
        "\n",
        "        # Layer 3b\n",
        "        x1 = F.relu(self.c3b1(x))\n",
        "        x2 = F.relu(self.c3b22(F.relu(self.c3b21(x))))\n",
        "        x3 = F.relu(self.c3b32(F.relu(self.c3b31(x))))\n",
        "        x4 = F.relu(self.c3b4(self.mp3b4(x)))\n",
        "        x = self.mp3(torch.cat((x1, x2, x3, x4), 1))\n",
        "\n",
        "        # Layer 4a\n",
        "        x1 = F.relu(self.c4a1(x))\n",
        "        x2 = F.relu(self.c4a22(F.relu(self.c4a21(x))))\n",
        "        x3 = F.relu(self.c4a32(F.relu(self.c4a31(x))))\n",
        "        x4 = F.relu(self.c4a4(self.mp4a4(x)))\n",
        "        x = torch.cat((x1, x2, x3, x4), 1)\n",
        "\n",
        "        # Auxiliary 1\n",
        "        if auxiliary == True:\n",
        "            z1 = self.flat1(F.relu(self.ca1(self.apa1(x))))\n",
        "            z1 = self.a1out(self.a1drop(F.relu(self.fca1(z1))))\n",
        "        else:\n",
        "            z1 = None\n",
        "\n",
        "        # Layer 4b\n",
        "        x1 = F.relu(self.c4b1(x))\n",
        "        x2 = F.relu(self.c4b22(F.relu(self.c4b21(x))))\n",
        "        x3 = F.relu(self.c4b32(F.relu(self.c4b31(x))))\n",
        "        x4 = F.relu(self.c4b4(self.mp4b4(x)))\n",
        "        x = torch.cat((x1, x2, x3, x4), 1)\n",
        "\n",
        "        # Layer 4c\n",
        "        x1 = F.relu(self.c4c1(x))\n",
        "        x2 = F.relu(self.c4c22(F.relu(self.c4c21(x))))\n",
        "        x3 = F.relu(self.c4c32(F.relu(self.c4c31(x))))\n",
        "        x4 = F.relu(self.c4c4(self.mp4c4(x)))\n",
        "        x = torch.cat((x1, x2, x3, x4), 1)\n",
        "\n",
        "        # Layer 4d\n",
        "        x1 = F.relu(self.c4d1(x))\n",
        "        x2 = F.relu(self.c4d22(F.relu(self.c4d21(x))))\n",
        "        x3 = F.relu(self.c4d32(F.relu(self.c4d31(x))))\n",
        "        x4 = F.relu(self.c4d4(self.mp4d4(x)))\n",
        "        x = torch.cat((x1, x2, x3, x4), 1)\n",
        "\n",
        "        # Auxiliary 2\n",
        "        if auxiliary == True:\n",
        "            z2 = self.flat(F.relu(self.ca2(self.apa2(x))))\n",
        "            z2 = self.a2out(self.a2drop(F.relu(self.fca2(z2))))\n",
        "        else:\n",
        "            z2 = None\n",
        "\n",
        "        # Layer 4e\n",
        "        x1 = F.relu(self.c4e1(x))\n",
        "        x2 = F.relu(self.c4e22(F.relu(self.c4e21(x))))\n",
        "        x3 = F.relu(self.c4e32(F.relu(self.c4e31(x))))\n",
        "        x4 = F.relu(self.c4e4(self.mp4e4(x)))\n",
        "        x = self.mp4(torch.cat((x1, x2, x3, x4), 1))\n",
        "\n",
        "        # Layer 5a\n",
        "        x1 = F.relu(self.c5a1(x))\n",
        "        x2 = F.relu(self.c5a22(F.relu(self.c5a21(x))))\n",
        "        x3 = F.relu(self.c5a32(F.relu(self.c5a31(x))))\n",
        "        x4 = F.relu(self.c5a4(self.mp5a4(x)))\n",
        "        x = torch.cat((x1, x2, x3, x4), 1)\n",
        "\n",
        "        # Layer 5b\n",
        "        x1 = F.relu(self.c5b1(x))\n",
        "        x2 = F.relu(self.c5b22(F.relu(self.c5b21(x))))\n",
        "        x3 = F.relu(self.c5b32(F.relu(self.c5b31(x))))\n",
        "        x4 = F.relu(self.c5b4(self.mp5b4(x)))\n",
        "        x = torch.cat((x1, x2, x3, x4), 1)\n",
        "\n",
        "        # Final Output\n",
        "        x = self.out(self.flat(self.drop(self.ap(x))))\n",
        "\n",
        "        return x, z1, z2\n",
        "\n",
        "    \n",
        "    def predict(self, x):\n",
        "\n",
        "        y_hat = self.forward(x)\n",
        "        y_hat = torch.argmax(y_hat, axis=1)\n",
        "        return y_hat"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOTtnofE32ZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# googlenet = models.googlenet(pretrained=True)\n",
        "# pickle.dump(googlenet, open('/content/drive/My Drive/google_init.sav', 'wb'))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnTY_tSQ5Zt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "googlenet = pickle.load(open('/content/drive/My Drive/google_init.sav', 'rb'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k-5ltA0Q2kdX",
        "colab": {}
      },
      "source": [
        "classifier = GoogLeNet(7, RGB_mean)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yrvxmk_5pNL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "832e2db8-b0ff-4ffb-9d13-453ff01a8c8e"
      },
      "source": [
        "params = list(googlenet.parameters())\n",
        "len(params)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "173"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo6APIXm53j9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = list(googlenet.parameters())\n",
        "\n",
        "with torch.no_grad():\n",
        "    \n",
        "    classifier.c1.weight = params[0]\n",
        "    # classifier.c1.bias = params[1]\n",
        "\n",
        "    classifier.c21.weight = params[3]\n",
        "    # classifier.c21.bias = params[4]\n",
        "    classifier.c22.weight = params[6]\n",
        "    # classifier.c22.bias = params[7]\n",
        "\n",
        "    classifier.c3a1.weight = params[9]\n",
        "    # classifier.c3a1.bias = params[10]\n",
        "    classifier.c3a21.weight = params[12]\n",
        "    # classifier.c3a21.bias = params[13]\n",
        "    classifier.c3a22.weight = params[15]\n",
        "    # classifier.c3a22.bias = params[16]\n",
        "    classifier.c3a31.weight = params[18]\n",
        "    # classifier.c3a31.bias = params[19]\n",
        "    classifier.c3a32.weight = params[21]\n",
        "    # classifier.c3a32.bias = params[22]\n",
        "    classifier.c3a4.weight = params[24]\n",
        "    # classifier.c3a4.bias = params[25]\n",
        "    \n",
        "    classifier.c3b1.weight = params[27]\n",
        "    # classifier.c3b1.bias = params[28]\n",
        "    classifier.c3b21.weight = params[30]\n",
        "    # classifier.c3b21.bias = params[31]\n",
        "    classifier.c3b22.weight = params[33]\n",
        "    # classifier.c3b22.bias = params[34]\n",
        "    classifier.c3b31.weight = params[36]\n",
        "    # classifier.c3b31.bias = params[37]\n",
        "    classifier.c3b32.weight = params[39]\n",
        "    # classifier.c3b32.bias = params[40]\n",
        "    classifier.c3b4.weight = params[42]\n",
        "    # classifier.c3b4.bias = params[43]\n",
        "    \n",
        "    classifier.c4a1.weight = params[45]\n",
        "    # classifier.c4a1.bias = params[46]\n",
        "    classifier.c4a21.weight = params[48]\n",
        "    # classifier.c4a21.bias = params[49]\n",
        "    classifier.c4a22.weight = params[51]\n",
        "    # classifier.c4a22.bias = params[52]\n",
        "    classifier.c4a31.weight = params[54]\n",
        "    # classifier.c4a31.bias = params[55]\n",
        "    classifier.c4a32.weight = params[57]\n",
        "    # classifier.c4a32.bias = params[58]\n",
        "    classifier.c4a4.weight = params[60]\n",
        "    # classifier.c4a4.bias = params[61]\n",
        "\n",
        "    classifier.c4b1.weight = params[63]\n",
        "    # classifier.c4b1.bias = params[64]\n",
        "    classifier.c4b21.weight = params[66]\n",
        "    # classifier.c4b21.bias = params[67]\n",
        "    classifier.c4b22.weight = params[69]\n",
        "    # classifier.c4b22.bias = params[70]\n",
        "    classifier.c4b31.weight = params[72]\n",
        "    # classifier.c4b31.bias = params[73]\n",
        "    classifier.c4b32.weight = params[75]\n",
        "    # classifier.c4b32.bias = params[76]\n",
        "    classifier.c4b4.weight = params[78]\n",
        "    # classifier.c4b4.bias = params[79]\n",
        "\n",
        "    classifier.c4c1.weight = params[81]\n",
        "    # classifier.c4c1.bias = params[82]\n",
        "    classifier.c4c21.weight = params[84]\n",
        "    # classifier.c4c21.bias = params[85]\n",
        "    classifier.c4c22.weight = params[87]\n",
        "    # classifier.c4c22.bias = params[88]\n",
        "    classifier.c4c31.weight = params[90]\n",
        "    # classifier.c4c31.bias = params[91]\n",
        "    classifier.c4c32.weight = params[93]\n",
        "    # classifier.c4c32.bias = params[94]\n",
        "    classifier.c4c4.weight = params[96]\n",
        "    # classifier.c4c4.bias = params[97]\n",
        "\n",
        "    classifier.c4d1.weight = params[99]\n",
        "    # classifier.c4d1.bias = params[100]\n",
        "    classifier.c4d21.weight = params[102]\n",
        "    # classifier.c4d21.bias = params[103]\n",
        "    classifier.c4d22.weight = params[105]\n",
        "    # classifier.c4d22.bias = params[106]\n",
        "    classifier.c4d31.weight = params[108]\n",
        "    # classifier.c4d31.bias = params[109]\n",
        "    classifier.c4d32.weight = params[111]\n",
        "    # classifier.c4d32.bias = params[112]\n",
        "    classifier.c4d4.weight = params[114]\n",
        "    # classifier.c4d4.bias = params[115]\n",
        "\n",
        "    classifier.c4e1.weight = params[117]\n",
        "    # classifier.c4e1.bias = params[118]\n",
        "    classifier.c4e21.weight = params[120]\n",
        "    # classifier.c4e21.bias = params[121]\n",
        "    classifier.c4e22.weight = params[123]\n",
        "    # classifier.c4e22.bias = params[124]\n",
        "    classifier.c4e31.weight = params[126]\n",
        "    # classifier.c4e31.bias = params[127]\n",
        "    classifier.c4e32.weight = params[129]\n",
        "    # classifier.c4e32.bias = params[130]\n",
        "    classifier.c4e4.weight = params[132]\n",
        "    # classifier.c4e4.bias = params[133]\n",
        "\n",
        "    classifier.c5a1.weight = params[135]\n",
        "    # classifier.c5a1.bias = params[136]\n",
        "    classifier.c5a21.weight = params[138]\n",
        "    # classifier.c5a21.bias = params[139]\n",
        "    classifier.c5a22.weight = params[141]\n",
        "    # classifier.c5a22.bias = params[142]\n",
        "    classifier.c5a31.weight = params[144]\n",
        "    # classifier.c5a31.bias = params[145]\n",
        "    classifier.c5a32.weight = params[147]\n",
        "    # classifier.c5a32.bias = params[148]\n",
        "    classifier.c5a4.weight = params[150]\n",
        "    # classifier.c5a4.bias = params[151]\n",
        "\n",
        "    classifier.c5b1.weight = params[153]\n",
        "    # classifier.c5b1.bias = params[154]\n",
        "    classifier.c5b21.weight = params[156]\n",
        "    # classifier.c5b21.bias = params[157]\n",
        "    classifier.c5b22.weight = params[159]\n",
        "    # classifier.c5b22.bias = params[160]\n",
        "    classifier.c5b31.weight = params[162]\n",
        "    # classifier.c5b31.bias = params[163]\n",
        "    classifier.c5b32.weight = params[165]\n",
        "    # classifier.c5b32.bias = params[166]\n",
        "    classifier.c5b4.weight = params[168]\n",
        "    # classifier.c5b4.bias = params[169]\n",
        "\n",
        "classifier = classifier.to(device)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QOH2pEviO6nE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f711e0ea-d332-4140-dc09-f521873e7421"
      },
      "source": [
        "old_loss = np.inf\n",
        "\n",
        "max_epoch = 200\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for data in trainloader:\n",
        "        \n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward\n",
        "        y_hat, y_hat1, y_hat2 = classifier(X)\n",
        "        \n",
        "        # Calculate Loss (Cross Entropy)\n",
        "        loss_main = criterion(y_hat, y)\n",
        "        loss1 = criterion(y_hat1, y)\n",
        "        loss2 = criterion(y_hat2, y)\n",
        "\n",
        "        # Weighted Loss\n",
        "        loss = loss_main + 0.3*loss1 + 0.3*loss2\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update Parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()*len(X)/train_size\n",
        "    \n",
        "    print('Epoch', epoch+1, ': Loss =', running_loss)\n",
        "    \n",
        "    if abs(running_loss-old_loss)/running_loss < 1e-5:\n",
        "        print('Converged')\n",
        "        break\n",
        "    \n",
        "    old_loss = running_loss\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 : Loss = 3.114164891558657\n",
            "Epoch 2 : Loss = 3.1070855727179127\n",
            "Epoch 3 : Loss = 3.1008616324501173\n",
            "Epoch 4 : Loss = 3.0928819270914856\n",
            "Epoch 5 : Loss = 3.087354068556729\n",
            "Epoch 6 : Loss = 3.0741828808801097\n",
            "Epoch 7 : Loss = 3.0617434563121733\n",
            "Epoch 8 : Loss = 3.0521041516227587\n",
            "Epoch 9 : Loss = 3.0393812398877293\n",
            "Epoch 10 : Loss = 3.0214551516941617\n",
            "Epoch 11 : Loss = 3.0059534622817092\n",
            "Epoch 12 : Loss = 2.9883755059192403\n",
            "Epoch 13 : Loss = 2.972676259715383\n",
            "Epoch 14 : Loss = 2.951549646331043\n",
            "Epoch 15 : Loss = 2.9357256972415935\n",
            "Epoch 16 : Loss = 2.9082695216667362\n",
            "Epoch 17 : Loss = 2.900797851409646\n",
            "Epoch 18 : Loss = 2.882651125512472\n",
            "Epoch 19 : Loss = 2.8517972617199194\n",
            "Epoch 20 : Loss = 2.836704524967313\n",
            "Epoch 21 : Loss = 2.8317301265038677\n",
            "Epoch 22 : Loss = 2.791455719113766\n",
            "Epoch 23 : Loss = 2.7727573424681555\n",
            "Epoch 24 : Loss = 2.752363189172246\n",
            "Epoch 25 : Loss = 2.7383268843129116\n",
            "Epoch 26 : Loss = 2.7007741911486054\n",
            "Epoch 27 : Loss = 2.6703251297050237\n",
            "Epoch 28 : Loss = 2.6565201947082624\n",
            "Epoch 29 : Loss = 2.617461485314452\n",
            "Epoch 30 : Loss = 2.6002346621988544\n",
            "Epoch 31 : Loss = 2.5734068649571116\n",
            "Epoch 32 : Loss = 2.5618787642555367\n",
            "Epoch 33 : Loss = 2.497834094310056\n",
            "Epoch 34 : Loss = 2.4813279382858546\n",
            "Epoch 35 : Loss = 2.4659555797377526\n",
            "Epoch 36 : Loss = 2.45472989348169\n",
            "Epoch 37 : Loss = 2.481543823401687\n",
            "Epoch 38 : Loss = 2.391500836050054\n",
            "Epoch 39 : Loss = 2.3572277524330056\n",
            "Epoch 40 : Loss = 2.3700497607320856\n",
            "Epoch 41 : Loss = 2.3281036735827083\n",
            "Epoch 42 : Loss = 2.320310183933803\n",
            "Epoch 43 : Loss = 2.2729424848789117\n",
            "Epoch 44 : Loss = 2.2150567898766917\n",
            "Epoch 45 : Loss = 2.2325337547873785\n",
            "Epoch 46 : Loss = 2.2710043877259363\n",
            "Epoch 47 : Loss = 2.203270403765635\n",
            "Epoch 48 : Loss = 2.181684011366309\n",
            "Epoch 49 : Loss = 2.139806162604887\n",
            "Epoch 50 : Loss = 2.1136757089701264\n",
            "Epoch 51 : Loss = 2.105359918149091\n",
            "Epoch 52 : Loss = 2.147679130374762\n",
            "Epoch 53 : Loss = 2.0997232776070307\n",
            "Epoch 54 : Loss = 2.0563335368857567\n",
            "Epoch 55 : Loss = 2.026299391058679\n",
            "Epoch 56 : Loss = 1.9909525997547322\n",
            "Epoch 57 : Loss = 1.9853701678718008\n",
            "Epoch 58 : Loss = 1.9824801430054242\n",
            "Epoch 59 : Loss = 1.9572641301238165\n",
            "Epoch 60 : Loss = 1.929835555030078\n",
            "Epoch 61 : Loss = 1.887351133266808\n",
            "Epoch 62 : Loss = 1.8891689154329203\n",
            "Epoch 63 : Loss = 1.8791371097963447\n",
            "Epoch 64 : Loss = 1.860679300819955\n",
            "Epoch 65 : Loss = 1.8561413790706143\n",
            "Epoch 66 : Loss = 1.820932576049911\n",
            "Epoch 67 : Loss = 1.7972270221244997\n",
            "Epoch 68 : Loss = 1.8053835842252193\n",
            "Epoch 69 : Loss = 1.7923335152636006\n",
            "Epoch 70 : Loss = 1.8187335692216295\n",
            "Epoch 71 : Loss = 1.804353243797914\n",
            "Epoch 72 : Loss = 1.7536031709730833\n",
            "Epoch 73 : Loss = 1.7020725231968152\n",
            "Epoch 74 : Loss = 1.7040844216994708\n",
            "Epoch 75 : Loss = 1.6503892385170433\n",
            "Epoch 76 : Loss = 1.7305188212245184\n",
            "Epoch 77 : Loss = 1.7450749982109468\n",
            "Epoch 78 : Loss = 1.652061451602896\n",
            "Epoch 79 : Loss = 1.5868282264117992\n",
            "Epoch 80 : Loss = 1.5664105863936686\n",
            "Epoch 81 : Loss = 1.555963538664974\n",
            "Epoch 82 : Loss = 1.5564548690975337\n",
            "Epoch 83 : Loss = 1.5491725700657544\n",
            "Epoch 84 : Loss = 1.5821925517989368\n",
            "Epoch 85 : Loss = 1.497296652312063\n",
            "Epoch 86 : Loss = 1.5098466399654693\n",
            "Epoch 87 : Loss = 1.4700869533658443\n",
            "Epoch 88 : Loss = 1.4616740152810923\n",
            "Epoch 89 : Loss = 1.395735138800086\n",
            "Epoch 90 : Loss = 1.3929992764669015\n",
            "Epoch 91 : Loss = 1.4263702435775916\n",
            "Epoch 92 : Loss = 1.4474953986211105\n",
            "Epoch 93 : Loss = 1.455087686664967\n",
            "Epoch 94 : Loss = 1.3786828638369195\n",
            "Epoch 95 : Loss = 1.322910831780384\n",
            "Epoch 96 : Loss = 1.3131966262744277\n",
            "Epoch 97 : Loss = 1.2941745602710735\n",
            "Epoch 98 : Loss = 1.2972230454355167\n",
            "Epoch 99 : Loss = 1.2840966530377855\n",
            "Epoch 100 : Loss = 1.262917211662186\n",
            "Epoch 101 : Loss = 1.3137811106671855\n",
            "Epoch 102 : Loss = 1.2401672614160733\n",
            "Epoch 103 : Loss = 1.1710392510849423\n",
            "Epoch 104 : Loss = 1.1702445186804395\n",
            "Epoch 105 : Loss = 1.2411282590042008\n",
            "Epoch 106 : Loss = 1.236055223783965\n",
            "Epoch 107 : Loss = 1.175205091566159\n",
            "Epoch 108 : Loss = 1.1194210480314515\n",
            "Epoch 109 : Loss = 1.1517806364684153\n",
            "Epoch 110 : Loss = 1.1188003202764\n",
            "Epoch 111 : Loss = 1.1038752515972283\n",
            "Epoch 112 : Loss = 1.0948634808071815\n",
            "Epoch 113 : Loss = 1.0301928486973566\n",
            "Epoch 114 : Loss = 1.0347928290583115\n",
            "Epoch 115 : Loss = 1.0440286738531932\n",
            "Epoch 116 : Loss = 1.0343059382372202\n",
            "Epoch 117 : Loss = 1.0128486584287903\n",
            "Epoch 118 : Loss = 1.0192192464755387\n",
            "Epoch 119 : Loss = 1.0461003360847978\n",
            "Epoch 120 : Loss = 1.077719599943128\n",
            "Epoch 121 : Loss = 1.044527639495371\n",
            "Epoch 122 : Loss = 1.140457698692428\n",
            "Epoch 123 : Loss = 0.9652311056333136\n",
            "Epoch 124 : Loss = 0.9179218656510012\n",
            "Epoch 125 : Loss = 0.9139874533909125\n",
            "Epoch 126 : Loss = 0.9939189738097507\n",
            "Epoch 127 : Loss = 0.9411645845253708\n",
            "Epoch 128 : Loss = 0.8912072526453264\n",
            "Epoch 129 : Loss = 0.8931883521611682\n",
            "Epoch 130 : Loss = 0.9351477091320717\n",
            "Epoch 131 : Loss = 0.9283898759386682\n",
            "Epoch 132 : Loss = 0.8959997393943706\n",
            "Epoch 133 : Loss = 0.8315275961513718\n",
            "Epoch 134 : Loss = 0.823242922277816\n",
            "Epoch 135 : Loss = 1.0176947428374339\n",
            "Epoch 136 : Loss = 0.9488161536459307\n",
            "Epoch 137 : Loss = 0.9115370744612159\n",
            "Epoch 138 : Loss = 0.8301237879729854\n",
            "Epoch 139 : Loss = 0.983510213446534\n",
            "Epoch 140 : Loss = 0.9148912463038642\n",
            "Epoch 141 : Loss = 0.8190477891250769\n",
            "Epoch 142 : Loss = 0.7346407550967944\n",
            "Epoch 143 : Loss = 0.7889261791930382\n",
            "Epoch 144 : Loss = 0.7489415164193209\n",
            "Epoch 145 : Loss = 0.7266322505183337\n",
            "Epoch 146 : Loss = 0.7691964592252457\n",
            "Epoch 147 : Loss = 0.7743110885188139\n",
            "Epoch 148 : Loss = 0.7246580555879281\n",
            "Epoch 149 : Loss = 0.6815296554814647\n",
            "Epoch 150 : Loss = 0.6691411825007262\n",
            "Epoch 151 : Loss = 0.6448582996474741\n",
            "Epoch 152 : Loss = 0.6891368353408388\n",
            "Epoch 153 : Loss = 0.6781568427534469\n",
            "Epoch 154 : Loss = 0.6641850510956102\n",
            "Epoch 155 : Loss = 0.6593053521594935\n",
            "Epoch 156 : Loss = 0.706676258650391\n",
            "Epoch 157 : Loss = 0.6930970132143239\n",
            "Epoch 158 : Loss = 0.714377926617134\n",
            "Epoch 159 : Loss = 0.6871469500588208\n",
            "Epoch 160 : Loss = 0.7770653888323582\n",
            "Epoch 161 : Loss = 0.7459802320194577\n",
            "Epoch 162 : Loss = 0.6327192189386083\n",
            "Epoch 163 : Loss = 0.5927103566791122\n",
            "Epoch 164 : Loss = 0.579335680614365\n",
            "Epoch 165 : Loss = 0.5605530600722244\n",
            "Epoch 166 : Loss = 0.5755763709129773\n",
            "Epoch 167 : Loss = 0.5892543042993712\n",
            "Epoch 168 : Loss = 0.5781470848708203\n",
            "Epoch 169 : Loss = 0.5790680045657872\n",
            "Epoch 170 : Loss = 0.6221101373330226\n",
            "Epoch 171 : Loss = 0.6559620491303634\n",
            "Epoch 172 : Loss = 0.670529244461126\n",
            "Epoch 173 : Loss = 0.5690153386534713\n",
            "Epoch 174 : Loss = 0.6911459791535699\n",
            "Epoch 175 : Loss = 0.6515387097302214\n",
            "Epoch 176 : Loss = 0.6163048430602309\n",
            "Epoch 177 : Loss = 0.574978632586343\n",
            "Epoch 178 : Loss = 0.5057919421054761\n",
            "Epoch 179 : Loss = 0.504611729537153\n",
            "Epoch 180 : Loss = 0.47381553458835185\n",
            "Epoch 181 : Loss = 0.5205522052917747\n",
            "Epoch 182 : Loss = 0.46077300769111423\n",
            "Epoch 183 : Loss = 0.4715040797555904\n",
            "Epoch 184 : Loss = 0.44748424247997565\n",
            "Epoch 185 : Loss = 0.4567675709932108\n",
            "Epoch 186 : Loss = 0.5843956190119222\n",
            "Epoch 187 : Loss = 0.5728941534869763\n",
            "Epoch 188 : Loss = 0.5409638167258339\n",
            "Epoch 189 : Loss = 0.5448195510625009\n",
            "Epoch 190 : Loss = 0.5051061998053294\n",
            "Epoch 191 : Loss = 0.45057798719572273\n",
            "Epoch 192 : Loss = 0.452789843705473\n",
            "Epoch 193 : Loss = 0.5659147800053453\n",
            "Epoch 194 : Loss = 0.4585727993204204\n",
            "Epoch 195 : Loss = 0.41614425514633235\n",
            "Epoch 196 : Loss = 0.45057742936270584\n",
            "Epoch 197 : Loss = 0.4051244987843344\n",
            "Epoch 198 : Loss = 0.4335389908805542\n",
            "Epoch 199 : Loss = 0.40366950838823346\n",
            "Epoch 200 : Loss = 0.4059490949850049\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVvSW-o33fn7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "57658c16-6a26-4319-dcd6-0ed4e8d8597f"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    train_loss = 0.0\n",
        "    y_train = []\n",
        "    y_train_pred = []\n",
        "\n",
        "    for data in trainloader:\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        y_hat, _, _ = classifier(X)      \n",
        "        train_loss += criterion(y_hat, y)*len(X)/train_size\n",
        "        \n",
        "        y_train.extend(list(y.detach().cpu().numpy()))\n",
        "        y_train_pred.extend(list(torch.argmax(y_hat, axis=1).detach().cpu().numpy()))\n",
        "\n",
        "print('Train Loss =', train_loss.item())\n",
        "pd.DataFrame(confusion_matrix(y_train, y_train_pred))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Loss = 0.3442017138004303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0   1   2   3   4   5   6\n",
              "0  40   0   0   2   1   0   3\n",
              "1   0  35   0   0   1   0   0\n",
              "2   0   0  44   2   0   0   0\n",
              "3   0   0   2  40   0   0   0\n",
              "4   0   1   0   0  36   4   0\n",
              "5   0   1   0   0   1  32   0\n",
              "6   1   0   0   2   1   1  37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylNoy_9_3fA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e9905af-cbc3-499b-ff81-a2b919f2796d"
      },
      "source": [
        "acc = accuracy_score(y_train, y_train_pred)\n",
        "prec = precision_score(y_train, y_train_pred, average='macro')\n",
        "f1 = f1_score(y_train, y_train_pred, average='macro')\n",
        "\n",
        "print('Train Accuracy =', acc, 'Train Precision =', prec, 'Train F1 =', f1)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy = 0.9198606271777003 Train Precision = 0.9196439319185873 Train F1 = 0.9195419073826858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ATw2OTqQiJCq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "b916122b-0c1a-49ec-82a2-1450400f1d59"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    test_loss = 0.0\n",
        "    y_test = []\n",
        "    y_test_pred = []\n",
        "\n",
        "    for data in testloader:\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        y_hat, _, _ = classifier(X)      \n",
        "        test_loss += criterion(y_hat, y)*len(X)/test_size\n",
        "        \n",
        "        y_test.extend(list(y.detach().cpu().numpy()))\n",
        "        y_test_pred.extend(list(torch.argmax(y_hat, axis=1).detach().cpu().numpy()))\n",
        "\n",
        "print('Test Loss =', test_loss.item())\n",
        "plt.imshow(confusion_matrix(y_test, y_test_pred), cmap='Reds')\n",
        "plt.show()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss = 2.0701448917388916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgq5cyyZ4m15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22cd6a0a-7dcb-4f12-b915-154158ea2034"
      },
      "source": [
        "acc = accuracy_score(y_test, y_test_pred)\n",
        "prec = precision_score(y_test, y_test_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "\n",
        "print('Test Accuracy =', acc, 'Test Precision =', prec, 'Test F1 =', f1)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy = 0.38095238095238093 Train Precision = 0.3436507936507937 Train F1 = 0.32754435107376284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s1RPoXsreDy4"
      },
      "source": [
        "### Question 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NuqwHPPlQavd",
        "colab": {}
      },
      "source": [
        "class CNN2(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_classes):\n",
        "        super(CNN2, self).__init__()\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        # 3x224x224\n",
        "        self.cl1 = nn.Conv2d(3, 4, 3, stride=1, padding=1)\n",
        "        # 4x224x224\n",
        "        self.pl1 = nn.AvgPool2d(2, stride=2)\n",
        "        # 4x112x112\n",
        "        self.cl2 = nn.Conv2d(4, 16, 3, stride=1, padding=1)\n",
        "        # 16x112x112\n",
        "        self.pl2 = nn.AvgPool2d(2, stride=2)\n",
        "\n",
        "        # 16x56x56\n",
        "        self.flat = nn.Flatten(1, -1)\n",
        "        # (16x56x56)x1\n",
        "        self.out = nn.Linear(16*56*56, self.n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.pl1(F.relu(self.cl1(x)))\n",
        "        x = self.pl2(F.relu(self.cl2(x)))\n",
        "        x = self.out(self.flat(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "\n",
        "        y_hat = self.forward(x)\n",
        "        y_hat = torch.argmax(y_hat, axis=1)\n",
        "        return y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y4dEykLIhv7s",
        "colab": {}
      },
      "source": [
        "classifier = CNN2(7)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(classifier.parameters(), lr=0.0001, momentum=0.9)\n",
        "classifier = classifier.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_3RX6TtEhMFp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "4ce92e13-ce65-4301-930e-5cccd21edd7e"
      },
      "source": [
        "old_loss = np.inf\n",
        "from IPython.display import clear_output\n",
        "losses = []\n",
        "max_epoch = 200\n",
        "for epoch in range(max_epoch):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for data in trainloader:\n",
        "            \n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward\n",
        "        y_hat = classifier(X)\n",
        "        \n",
        "        # Calculate Loss (Cross Entropy)\n",
        "        loss = criterion(y_hat, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update Parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()*len(X)/train_size\n",
        "\n",
        "    print('Epoch', epoch+1, ': Loss =', running_loss)\n",
        "    losses.append(running_loss)\n",
        "\n",
        "    \n",
        "    if (abs(running_loss-old_loss)/running_loss < 0.2) and epoch>=10 and running_loss<0.01:\n",
        "        print('Converged')\n",
        "        break\n",
        "    \n",
        "    old_loss = running_loss\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 : Loss = 8.51608510382915\n",
            "Epoch 2 : Loss = 1.9994171861987495\n",
            "Epoch 3 : Loss = 1.9447825997548651\n",
            "Epoch 4 : Loss = 1.9335377008657422\n",
            "Epoch 5 : Loss = 1.924046891906951\n",
            "Epoch 6 : Loss = 1.915209303749563\n",
            "Epoch 7 : Loss = 1.8966690609264043\n",
            "Epoch 8 : Loss = 1.880748568926954\n",
            "Epoch 9 : Loss = 1.8649288818811292\n",
            "Epoch 10 : Loss = 1.8444972038269043\n",
            "Epoch 11 : Loss = 1.8139404183065437\n",
            "Epoch 12 : Loss = 1.783672104729177\n",
            "Epoch 13 : Loss = 1.748245834888897\n",
            "Epoch 14 : Loss = 1.6984773778749263\n",
            "Epoch 15 : Loss = 1.6479445400969077\n",
            "Epoch 16 : Loss = 1.5252120798057796\n",
            "Epoch 17 : Loss = 1.3692599933737246\n",
            "Epoch 18 : Loss = 1.1686137353917032\n",
            "Epoch 19 : Loss = 0.993157974103602\n",
            "Epoch 20 : Loss = 0.7433030617777064\n",
            "Epoch 21 : Loss = 0.5656542364728576\n",
            "Epoch 22 : Loss = 0.4901453439366943\n",
            "Epoch 23 : Loss = 0.36426011267854774\n",
            "Epoch 24 : Loss = 0.3462182510812939\n",
            "Epoch 25 : Loss = 0.3036954419538119\n",
            "Epoch 26 : Loss = 0.10046271201002474\n",
            "Epoch 27 : Loss = 0.06260648136147225\n",
            "Epoch 28 : Loss = 0.04024827143482422\n",
            "Epoch 29 : Loss = 0.026623422656377016\n",
            "Epoch 30 : Loss = 0.01634821658532171\n",
            "Epoch 31 : Loss = 0.01191775640635021\n",
            "Epoch 32 : Loss = 0.009365431529563895\n",
            "Epoch 33 : Loss = 0.008167996201080104\n",
            "Converged\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RskMmPeG5RAU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "f000db14-7758-4968-c0c9-89cbcd23fcb1"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    train_loss = 0.0\n",
        "    y_train = []\n",
        "    y_train_pred = []\n",
        "\n",
        "    for data in trainloader:\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        y_hat = classifier(X)      \n",
        "        train_loss += criterion(y_hat, y)*len(X)/train_size\n",
        "        \n",
        "        y_train.extend(list(y.detach().cpu().numpy()))\n",
        "        y_train_pred.extend(list(torch.argmax(y_hat, axis=1).detach().cpu().numpy()))\n",
        "\n",
        "print('Train Loss =', train_loss.item())\n",
        "plt.imshow(confusion_matrix(y_train, y_train_pred), cmap='Reds')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Loss = 0.007632026448845863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAKXklEQVR4nO3d64tc9R3H8c8na0Sb2Ir1gs2GxgfWIooXQqAo1lqUWIMW2gcGFFoKImirtEW0T4r/gNgHpUWStBYvQYwBEesF1FqhXpIYq0nUhhBNUssaRTQWKuqnD/aErmninszOOTP99v2CkJ3dcb8/0feemTOz5+ckAlDHvFEvAMBwETVQDFEDxRA1UAxRA8Uc0cU3Xeh5OW7eaH5enHjWmSOZC/Rp55tvau/ed3ywr3US9XHz5unnR32pi289q58889RI5gJ9Wnr+hYf8Gg+/gWKIGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFiiBoohqiBYlpFbXu57ddsb7d9c9eLAjC4WaO2PSHp15IulXS6pJW2T+96YQAG0+ZIvUzS9iQ7knwkaa2kK7pdFoBBtYl6kaRdM27vbj73Gbavsb3B9oZ9XKEUGJmhnShLckeSpUmWLvRBf3cbQA/aRL1H0uIZtyebzwEYQ22ifkHSqbZPsX2kpCslPdjtsgAMatbLGSX52Pb1kh6VNCFpTZItna8MwEBaXaMsycOSHu54LQCGgHeUAcUQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFdLLr5YlnnTmy3Sf/tGR012/45s6tI5sN7MeRGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFiiBoohqiBYogaKIaogWLa7Hq5xvaU7Vf6WBCAuWlzpP69pOUdrwPAkMwadZKnJb3bw1oADMHQnlPP3Mr27b3vDOvbAjhMnWxle8LxXx7WtwVwmDj7DRRD1EAxbV7SulfSXySdZnu37R91vywAg2qzP/XKPhYCYDh4+A0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFNPJVrajNMrtZK9dMDmy2b/9cPfIZmO8cKQGiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgmDbX/V5s+0nbW21vsX1DHwsDMJg2v6X1saSfJdlk+xhJG20/nmR0vw4F4JDabGX7VpJNzccfSNomaVHXCwMwmMN6Tm17iaRzJD13kK+xlS0wBlpHbXuhpHWSbkzy/oFfZytbYDy0itr2fE0HfXeSB7pdEoC5aHP225JWS9qW5LbulwRgLtocqc+TdLWki2xvbv58p+N1ARhQm61sn5HkHtYCYAh4RxlQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UEy5rWxHaZTbyT60+Osjmy1JK3a9OtL5+A+O1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRTT5mL+R9l+3vZLzVa2t/axMACDafNbWv+SdFGSfc32O8/Y/mOSZzteG4ABtLmYfyTta27Ob/6ky0UBGFzbDfImbG+WNCXp8SRsZQuMqVZRJ/kkydmSJiUts33GQe7DVrbAGDiss99J3pP0pKTl3SwHwFy1Oft9gu1jm4+PlnSxJK5dA4ypNme/T5Z0p+0JTf8QuC/JQ90uC8Cg2pz9/qukc3pYC4Ah4B1lQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0Uw/7URYx6f+h1i742stnf2/P6yGaPI47UQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMa2jbvbTetE21/wGxtjhHKlvkLStq4UAGI62u15OSrpM0qpulwNgrtoeqW+XdJOkTw91B7ayBcZDmw3yVkiaSrLx8+7HVrbAeGhzpD5P0uW2d0paK+ki23d1uioAA5s16iS3JJlMskTSlZKeSHJV5ysDMBBepwaKOaxrlCV5StJTnawEwFBwpAaKIWqgGKIGiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoBi2ssVQjHI72Xu/curIZq/8+99GNvtQOFIDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFtHrvd7M7xweSPpH0cZKlXS4KwOAO5xc6vpVkb2crATAUPPwGimkbdSQ9Znuj7WsOdge2sgXGQ9uoz09yrqRLJV1n+4ID78BWtsB4aBV1kj3N31OS1kta1uWiAAyuzabzC2wfs/9jSZdIeqXrhQEYTJuz3ydJWm97//3vSfJIp6sCMLBZo06yQ9JZPawFwBDwkhZQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8WwlS3+541yO9lrF0yOZO4b+uchv8aRGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFiiBoohqiBYogaKKZV1LaPtX2/7Vdtb7P9ja4XBmAwbX+h41eSHknyfdtHSvpCh2sCMAezRm37S5IukPQDSUrykaSPul0WgEG1efh9iqS3Jf3O9ou2VzV7an0GW9kC46FN1EdIOlfSb5KcI+lDSTcfeCe2sgXGQ5uod0vaneS55vb9mo4cwBiaNeok/5C0y/Zpzae+LWlrp6sCMLC2Z79/LOnu5sz3Dkk/7G5JAOaiVdRJNkta2vFaAAwB7ygDiiFqoBiiBoohaqAYogaKIWqgGKIGiiFqoBiiBoohaqAYJxn+N7XflvTGgP/48ZL2DnE5zGZ2xdlfTXLCwb7QSdRzYXtDkpG8z5zZzK4wm4ffQDFEDRQzjlHfwWxmM3twY/ecGsDcjOORGsAcEDVQzFhFbXu57ddsb7f9X5ch7nDuGttTtl/pa+aM2YttP2l7q+0ttm/ocfZRtp+3/VIz+9a+Zs9Yw0RzPfmHep670/bLtjfb3tDz7E63sRqb59S2JyS9LuliTV+W+AVJK5N0fuVS2xdI2ifpD0nO6HreAbNPlnRykk22j5G0UdJ3e/r3tqQFSfbZni/pGUk3JHm269kz1vBTTV//7otJVvQ4d6ekpUl6f/OJ7Tsl/TnJqv3bWCV5b1jff5yO1MskbU+yo9naZ62kK/oYnORpSe/2Mesgs99Ksqn5+ANJ2yQt6ml2kuxrbs5v/vT2U972pKTLJK3qa+aozdjGarU0vY3VMIOWxivqRZJ2zbi9Wz39zz0ubC+RdI6k5z7/nkOdOWF7s6QpSY/P2LShD7dLuknSpz3O3C+SHrO90fY1Pc5ttY3VXIxT1P/XbC+UtE7SjUne72tukk+SnC1pUtIy2708/bC9QtJUko19zDuI85OcK+lSSdc1T8H60Gobq7kYp6j3SFo84/Zk87nymuez6yTdneSBUayheQj4pKTlPY08T9LlzXPbtZIusn1XT7OVZE/z95Sk9Zp++teHzrexGqeoX5B0qu1TmpMHV0p6cMRr6lxzsmq1pG1Jbut59gm2j20+PlrTJylf7WN2kluSTCZZoun/1k8kuaqP2bYXNCcl1Tz0vURSL6989LGNVdttdzqX5GPb10t6VNKEpDVJtvQx2/a9ki6UdLzt3ZJ+mWR1H7M1fcS6WtLLzXNbSfpFkod7mH2ypDubVx7mSbovSa8vLY3ISZLWT/881RGS7knySI/zO93Gamxe0gIwHOP08BvAEBA1UAxRA8UQNVAMUQPFEDVQDFEDxfwbbdTOwW8pSkoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s1_WEeod6Bg2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1f2c8f9-6acb-401c-d029-0dca544e1bac"
      },
      "source": [
        "acc_tr = accuracy_score(y_train, y_train_pred)\n",
        "prec_tr = precision_score(y_train, y_train_pred, average='weighted')\n",
        "f1_tr = f1_score(y_train, y_train_pred, average='weighted')\n",
        "\n",
        "print('Train Accuracy =', acc_tr, 'Train Precision =', prec_tr, 'Train F1 =', f1_tr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy = 1.0 Train Precision = 1.0 Train F1 = 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Uf2CJP5jrId",
        "colab_type": "code",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5864ba77-5740-4bc4-b682-aa2e6f9ae5f5"
      },
      "source": [
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4eAKVd07iASJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a81f39e0-6cd6-43c7-949e-9b39eea22f4b"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    test_loss = 0.0\n",
        "    y_test = []\n",
        "    y_test_pred = []\n",
        "\n",
        "    for data in testloader:\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        y_hat = classifier(X)      \n",
        "        test_loss += criterion(y_hat, y)*len(X)/test_size\n",
        "        \n",
        "        y_test.extend(list(y.detach().cpu().numpy()))\n",
        "        y_test_pred.extend(list(torch.argmax(y_hat, axis=1).detach().cpu().numpy()))\n",
        "\n",
        "print('Test Loss =', test_loss.item())\n",
        "plt.imshow(confusion_matrix(y_test, y_test_pred), cmap='Reds')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss = 3.1113786697387695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALBklEQVR4nO3d/6vdBR3H8dfLO0VdlulUhlebP4QgUSljkkqYkcyU7IcQDYUikKBiUiDaL+E/IDOIYqhl6JSRDkTMElJMKnWbM79shcjSOxbX+QWdPzQ2X/1wP9JVt93PPfd8Pp/Du+cDLvece84+7/c9Z6/7+XLO+bydRADqOGroBgCMF6EGiiHUQDGEGiiGUAPFLOtioStWnJxVZ57ZxaIX9tbsMHWH9ulTh+5gOEM+5wM97rtefVV7977hQ93WSahXnXmmtjz5eBeLXtDBTbcNUndoU1etG7qFwQz5nA/1uK++6OLD3sbmN1AMoQaKIdRAMYQaKIZQA8UQaqAYQg0UQ6iBYgg1UAyhBooh1EAxrUJte63tf9h+2fZNXTcFYHQLhtr2lKRfSLpM0jmSrrF9TteNARhNmzX1GkkvJ3klyX5J90m6stu2AIyqTahPl/TavOszzc8+xPb1trfY3vL63jfG1R+ARRrbgbIkG5KsTrL6lBUnj2uxABapTah3Szpj3vXp5mcAJlCbUD8j6bO2z7J9jKSrJT3YbVsARrXg6YySHLD9Q0l/kDQl6c4kL3beGYCRtDpHWZKHJT3ccS8AxoB3lAHFEGqgGEINFEOogWIINVAMoQaKIdRAMYQaKIZQA8V0MvVSb80ONolwz/qNg9SVpOm/PDVY7aGnffK49+wI43tZUwPFEGqgGEINFEOogWIINVAMoQaKIdRAMYQaKIZQA8UQaqAYQg0UQ6iBYtpMvbzT9qztF/poCMDStFlT/0bS2o77ADAmC4Y6yROS3uyhFwBjMLZ96g+Nsn33vXEtFsAidTPK9oTl41osgEXi6DdQDKEGimnzkta9kv4q6WzbM7a/131bAEbVZj71NX00AmA82PwGiiHUQDGEGiiGUAPFEGqgGEINFEOogWIINVAMoQaK6WaU7YCGHGs6c8H5g9Ue2pCP+5Cmrlo3TOGfbz7sTaypgWIINVAMoQaKIdRAMYQaKIZQA8UQaqAYQg0UQ6iBYgg1UAyhBooh1EAxbc77fYbtx2y/ZPtF2wO9gx1AG20+pXVA0k+SbLN9gqStth9N8lLHvQEYQZtRtnuSbGsuvytph6TTu24MwGgWtU9te5WkcyV97MOzjLIFJkPrUNv+hKT7Jd2Q5J2P3s4oW2AytAq17aM1F+h7kjzQbUsAlqLN0W9LukPSjiS3dt8SgKVos6a+UNJ1ki6xvb35+nrHfQEYUZtRtk9Kcg+9ABgD3lEGFEOogWIINVAMoQaKIdRAMYQaKIZQA8UQaqAYQg0U080o20+fOtiIz4ObbhukriStvOHbg9Xes37jYLWHNuRzPtTjvv+fuw57G2tqoBhCDRRDqIFiCDVQDKEGiiHUQDGEGiiGUAPFEGqgGEINFEOogWIINVBMm5P5H2v7advPNaNsb+mjMQCjafMprf9IuiTJvmb8zpO2f5/kbx33BmAEbU7mH0n7mqtHN1/psikAo2s7IG/K9nZJs5IeTXLkUbZ73xh3nwBaahXqJAeTfFHStKQ1tj93iPv8b5TtipPH3SeAlhZ19DvJ25Iek7S2m3YALFWbo9+n2D6xuXycpK9J2tl1YwBG0+bo90pJd9me0twfgU1JHuq2LQCjanP0+++Szu2hFwBjwDvKgGIINVAMoQaKIdRAMYQaKIZQA8UQaqAYQg0UQ6iBYgg1UEwn86n379yhmQvO72LRC5r+y8c+6t2boX5nadjZ2JL0/eXTg9X+1Xszg9WeHmgO+zEXXXzY21hTA8UQaqAYQg0UQ6iBYgg1UAyhBooh1EAxhBoohlADxRBqoBhCDRTTOtTNPK1nbXPOb2CCLWZNvU7Sjq4aATAebadeTku6XNLt3bYDYKnarqnXS7pR0vuHu8P8UbZvHjg4luYALF6bAXlXSJpNsvVI95s/yvakZVNjaxDA4rRZU18o6Ru2d0m6T9Iltu/utCsAI1sw1EluTjKdZJWkqyX9Kcm1nXcGYCS8Tg0Us6hzlCV5XNLjnXQCYCxYUwPFEGqgGEINFEOogWIINVAMoQaKIdRAMYQaKIZQA8UQaqCYTkbZDungptsGqz3kONk96zcOVlsadpzskM/51ECjbI+ENTVQDKEGiiHUQDGEGiiGUAPFEGqgGEINFEOogWIINVAMoQaKIdRAMa3e+91M53hX0kFJB5Ks7rIpAKNbzAc6vpJkb2edABgLNr+BYtqGOpL+aHur7esPdQdG2QKToe3m90VJdts+VdKjtncmeWL+HZJskLRBkj5//LEZc58AWmq1pk6yu/k+K2mzpDVdNgVgdG2Gzi+3fcIHlyVdKumFrhsDMJo2m9+nSdps+4P7b0zySKddARjZgqFO8oqkL/TQC4Ax4CUtoBhCDRRDqIFiCDVQDKEGiiHUQDGEGiiGUAPFEGqgGEINFFNulO2QhhxrunKwysMb8nEfbIzuW7OHvYk1NVAMoQaKIdRAMYQaKIZQA8UQaqAYQg0UQ6iBYgg1UAyhBooh1EAxrUJt+0Tbv7O90/YO21/qujEAo2n7gY7bJD2S5Fu2j5F0fIc9AViCBUNt+1OSvizpO5KUZL+k/d22BWBUbTa/z5L0uqRf237W9u3NTK0PYZQtMBnahHqZpPMk/TLJuZLek3TTR++UZEOS1UlWn7RsasxtAmirTahnJM0keaq5/jvNhRzABFow1En+Lek122c3P/qqpJc67QrAyNoe/f6RpHuaI9+vSPpudy0BWIpWoU6yXdLqjnsBMAa8owwohlADxRBqoBhCDRRDqIFiCDVQDKEGiiHUQDGEGiiGUAPFOMn4F2q/LulfI/7zFZL2jrEdalO7Yu3PJDnlUDd0EuqlsL0lySDvM6c2tSvUZvMbKIZQA8VMYqg3UJva1B7dxO1TA1iaSVxTA1gCQg0UM1Ghtr3W9j9sv2z7Y6ch7rDunbZnbb/QV815tc+w/Zjtl2y/aHtdj7WPtf207eea2rf0VXteD1PN+eQf6rnuLtvP295ue0vPtTsdYzUx+9S2pyT9U9LXNHda4mckXZOk8zOX2v6ypH2Sfpvkc13X+0jtlZJWJtlm+wRJWyV9s6ff25KWJ9ln+2hJT0pal+RvXdee18OPNXf+u08muaLHurskrU7S+5tPbN8l6c9Jbv9gjFWSt8e1/ElaU6+R9HKSV5rRPvdJurKPwkmekPRmH7UOUXtPkm3N5Xcl7ZB0ek+1k2Rfc/Xo5qu3v/K2pyVdLun2vmoObd4YqzukuTFW4wy0NFmhPl3Sa/Ouz6in/9yTwvYqSedKeurI9xxrzSnb2yXNSnp03tCGPqyXdKOk93us+YFI+qPtrbav77FuqzFWSzFJof6/ZvsTku6XdEOSd/qqm+Rgki9Kmpa0xnYvux+2r5A0m2RrH/UO4aIk50m6TNIPml2wPrQaY7UUkxTq3ZLOmHd9uvlZec3+7P2S7knywBA9NJuAj0la21PJCyV9o9m3vU/SJbbv7qm2kuxuvs9K2qy53b8+dD7GapJC/Yykz9o+qzl4cLWkBwfuqXPNwao7JO1IcmvPtU+xfWJz+TjNHaTc2UftJDcnmU6ySnPP9Z+SXNtHbdvLm4OSajZ9L5XUyysffYyxajt2p3NJDtj+oaQ/SJqSdGeSF/uobfteSRdLWmF7RtLPktzRR23NrbGuk/R8s28rST9N8nAPtVdKuqt55eEoSZuS9PrS0kBOk7R57u+plknamOSRHut3OsZqYl7SAjAek7T5DWAMCDVQDKEGiiHUQDGEGiiGUAPFEGqgmP8CRtP9eGSl6WYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qJK9h5xu4DjA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1934143c-b626-4505-c384-52d9bf3af7f2"
      },
      "source": [
        "acc = accuracy_score(y_test, y_test_pred)\n",
        "prec = precision_score(y_test, y_test_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "\n",
        "print('Test Accuracy =', acc, 'Test Precision =', prec, 'Test F1 =', f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy = 0.2619047619047619 Test Precision = 0.28922902494331065 Test F1 = 0.25354090354090353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_vIZ1K6eE33v"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jVC5hAh8E33x",
        "colab": {}
      },
      "source": [
        "class CNN3(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_classes, k=4):\n",
        "        super(CNN3, self).__init__()\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        # 3x224x224\n",
        "        self.cl1 = nn.Conv2d(3, 4, 3, stride=1, padding=1)\n",
        "        # 4x224x224\n",
        "        self.pl1 = nn.AvgPool2d(2, stride=2)\n",
        "        # 4x112x112\n",
        "        self.cl2 = nn.Conv2d(4, 16, 3, stride=1, padding=1)\n",
        "        # 16x112x112\n",
        "        self.pl2 = nn.AvgPool2d(2, stride=2)\n",
        "\n",
        "        # NetVLAD\n",
        "        self.K = k\n",
        "        self.nv_conv = nn.Conv2d(16, self.K, 1)\n",
        "        self.nv_soft_ass = nn.Softmax2d()\n",
        "\n",
        "        # NetVLAD Parameter\n",
        "        self.c = nn.Parameter(torch.rand(self.K, 16))\n",
        "        \n",
        "        # Flatten to get h\n",
        "        self.flat = nn.Flatten(1, -1)\n",
        "\n",
        "        # Output layer\n",
        "        self.out = nn.Linear(self.K*16, self.n_classes)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        # print(x.shape)\n",
        "        x = self.pl1(F.relu(self.cl1(x)))\n",
        "        # print(x.shape)\n",
        "        x = self.pl2(F.relu(self.cl2(x)))\n",
        "        # print(x.shape)\n",
        "        \n",
        "        # NetVLAD Step 1\n",
        "        a = self.nv_soft_ass(self.nv_conv(x))\n",
        "\n",
        "        # NetVLAD Step 2\n",
        "        for k in range(self.K):\n",
        "            a_k = a[:, k, :, :]\n",
        "            c_k = self.c[k, :]\n",
        "            temp = (x - c_k.reshape(1, -1, 1, 1))*a_k.unsqueeze(1)\n",
        "            z_k = torch.sum(temp, axis=(2, 3))\n",
        "            if k==0:\n",
        "                Z = z_k.unsqueeze(1)\n",
        "            else:\n",
        "                Z = torch.cat((Z, z_k.unsqueeze(1)), 1)\n",
        "        \n",
        "        # Flatten\n",
        "        Z = self.flat(Z)\n",
        "        # print('Z shape', Z.shape)\n",
        "        Z = self.out(Z)\n",
        "\n",
        "        return Z\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "\n",
        "        y_hat = self.forward(x)\n",
        "        y_hat = torch.argmax(y_hat, axis=1)\n",
        "        return y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2NO7TpyJE330",
        "colab": {}
      },
      "source": [
        "classifier = CNN3(7)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(classifier.parameters(), lr=0.0001, momentum=0.9)\n",
        "classifier = classifier.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tmxv4-HM1did",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e3a390f0-8156-403e-daa8-91280233a4fd"
      },
      "source": [
        "old_loss = np.inf\n",
        "from IPython.display import clear_output\n",
        "losses = []\n",
        "max_epoch = 200\n",
        "for epoch in range(max_epoch):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for data in trainloader:\n",
        "            \n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward\n",
        "        y_hat = classifier(X)\n",
        "        \n",
        "        # Calculate Loss (Cross Entropy)\n",
        "        loss = criterion(y_hat, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update Parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()*len(X)/train_size\n",
        "\n",
        "    print('Epoch', epoch+1, ': Loss =', running_loss)\n",
        "    losses.append(running_loss)\n",
        "\n",
        "    \n",
        "    if (abs(running_loss-old_loss)/running_loss < 0.2) and epoch>=10 and running_loss<0.01:\n",
        "        print('Converged')\n",
        "        break\n",
        "    \n",
        "    old_loss = running_loss\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 : Loss = 85807623.2677891\n",
            "Epoch 2 : Loss = 28301.72832507622\n",
            "Epoch 3 : Loss = 18408.02954186629\n",
            "Epoch 4 : Loss = 43676.23143510452\n",
            "Epoch 5 : Loss = 43213.82771668119\n",
            "Epoch 6 : Loss = 126600.11846689894\n",
            "Epoch 7 : Loss = 240719.85224303138\n",
            "Epoch 8 : Loss = 215393.4227324695\n",
            "Epoch 9 : Loss = 71398.49858449477\n",
            "Epoch 10 : Loss = 141169.75748584495\n",
            "Epoch 11 : Loss = 207208.68343042248\n",
            "Epoch 12 : Loss = 56377.06017258275\n",
            "Epoch 13 : Loss = 39714.29333623694\n",
            "Epoch 14 : Loss = 69156.5947027439\n",
            "Epoch 15 : Loss = 49089.8818121189\n",
            "Epoch 16 : Loss = 115871.9918336237\n",
            "Epoch 17 : Loss = 96327.01796602787\n",
            "Epoch 18 : Loss = 180568.33177264806\n",
            "Epoch 19 : Loss = 158264.56037674216\n",
            "Epoch 20 : Loss = 189712.8424978223\n",
            "Epoch 21 : Loss = 186683.625\n",
            "Epoch 22 : Loss = 348658.04322735185\n",
            "Epoch 23 : Loss = 444821.3343858886\n",
            "Epoch 24 : Loss = 376555.8679224739\n",
            "Epoch 25 : Loss = 439843.20198170736\n",
            "Epoch 26 : Loss = 271717.7355182927\n",
            "Epoch 27 : Loss = 346034.916104094\n",
            "Epoch 28 : Loss = 582051.9578614983\n",
            "Epoch 29 : Loss = 458804.6652874565\n",
            "Epoch 30 : Loss = 782716.6406794424\n",
            "Epoch 31 : Loss = 737370.8886106273\n",
            "Epoch 32 : Loss = 1109940.2602351916\n",
            "Epoch 33 : Loss = 1259644.2229965155\n",
            "Epoch 34 : Loss = 1218806.8020470385\n",
            "Epoch 35 : Loss = 1253718.5966898955\n",
            "Epoch 36 : Loss = 1410611.5966898955\n",
            "Epoch 37 : Loss = 1033366.2402003484\n",
            "Epoch 38 : Loss = 890387.5984320558\n",
            "Epoch 39 : Loss = 919064.6055095819\n",
            "Epoch 40 : Loss = 1764849.037456446\n",
            "Epoch 41 : Loss = 2898772.5217770035\n",
            "Epoch 42 : Loss = 1614562.4259581878\n",
            "Epoch 43 : Loss = 1797812.1681184666\n",
            "Epoch 44 : Loss = 2174955.413763066\n",
            "Epoch 45 : Loss = 1540044.131533101\n",
            "Epoch 46 : Loss = 1730273.8837108014\n",
            "Epoch 47 : Loss = 1958297.656794425\n",
            "Epoch 48 : Loss = 1609277.43793554\n",
            "Epoch 49 : Loss = 2174077.093858885\n",
            "Epoch 50 : Loss = 2493788.206010453\n",
            "Epoch 51 : Loss = 2400234.141768293\n",
            "Epoch 52 : Loss = 2040736.8732578398\n",
            "Epoch 53 : Loss = 2971595.155923345\n",
            "Epoch 54 : Loss = 4200028.503484321\n",
            "Epoch 55 : Loss = 8876385.809233451\n",
            "Epoch 56 : Loss = 11815059.135888502\n",
            "Epoch 57 : Loss = 5941518.754355401\n",
            "Epoch 58 : Loss = 11030383.993031358\n",
            "Epoch 59 : Loss = 16088955.707317073\n",
            "Epoch 60 : Loss = 16107798.655052265\n",
            "Epoch 61 : Loss = 25727843.770034846\n",
            "Epoch 62 : Loss = 29940467.972125437\n",
            "Epoch 63 : Loss = 47400227.72125436\n",
            "Epoch 64 : Loss = 66212622.773519166\n",
            "Epoch 65 : Loss = 53510676.153310105\n",
            "Epoch 66 : Loss = 33647129.31010453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAJMMT7Z0_Ri",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "522c15f7-3340-4a72-f00c-8e2ce384dd52"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    train_loss = 0.0\n",
        "    y_train = []\n",
        "    y_train_pred = []\n",
        "\n",
        "    for data in trainloader:\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        y_hat = classifier(X)      \n",
        "        train_loss += criterion(y_hat, y)*len(X)/train_size\n",
        "        \n",
        "        y_train.extend(list(y.detach().cpu().numpy()))\n",
        "        y_train_pred.extend(list(torch.argmax(y_hat, axis=1).detach().cpu().numpy()))\n",
        "\n",
        "print('Train Loss =', train_loss.item())\n",
        "plt.imshow(confusion_matrix(y_train, y_train_pred), cmap='Reds')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Loss = 21922.796875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsXfxUyu1OJm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c3a72c9d-8c46-4da8-87f9-5b876309617a"
      },
      "source": [
        "acc_tr = accuracy_score(y_train, y_train_pred)\n",
        "prec_tr = precision_score(y_train, y_train_pred, average='weighted')\n",
        "f1_tr = f1_score(y_train, y_train_pred, average='weighted')\n",
        "\n",
        "print('Train Accuracy =', acc_tr, 'Train Precision =', prec_tr, 'Train F1 =', f1_tr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy = 0.13240418118466898 Train Precision = 0.017530867195182653 Train F1 = 0.030962208523184133\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lcw20TIlE334",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "20e16188-c826-4eed-af1b-6afda2df8118"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    test_loss = 0.0\n",
        "    y_test = []\n",
        "    y_test_pred = []\n",
        "\n",
        "    for data in testloader:\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        y_hat = classifier(X)      \n",
        "        test_loss += criterion(y_hat, y)\n",
        "        \n",
        "        y_test.extend(list(y.detach().cpu().numpy()))\n",
        "        y_test_pred.extend(list(torch.argmax(y_hat, axis=1).detach().cpu().numpy()))\n",
        "\n",
        "print('Test Loss =', test_loss.item())\n",
        "plt.imshow(confusion_matrix(y_test, y_test_pred), cmap='Reds')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss = 57528.66796875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FckLra-d1Ulv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = accuracy_score(y_test, y_test_pred)\n",
        "prec = precision_score(y_test, y_test_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "\n",
        "print('Test Accuracy =', acc, 'Test Precision =', prec, 'Test F1 =', f1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}