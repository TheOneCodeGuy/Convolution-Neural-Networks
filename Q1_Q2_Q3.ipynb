{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Q1_Q2_Q3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7_qTq010ijWD"
      },
      "source": [
        "### Run this cell only once (the first ever time you run) to process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v8PCDpQkAHwN",
        "colab": {}
      },
      "source": [
        "# # from google.colab import drive\n",
        "# # drive.mount('/content/drive')\n",
        "\n",
        "# # For extracting\n",
        "# !pip install pyunpack\n",
        "# !pip install patool\n",
        "\n",
        "# from pyunpack import Archive\n",
        "# Archive('CUB_200_2011.tgz').extractall('Assignment3_Data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fjjzGKEwFmsN",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Z5GNnFsDPna",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "369b647f-0c9f-4a7a-82fa-6229d78d7967"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import tarfile\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from io import StringIO\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
        "import pickle\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J6JD3ycyPuYi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c900ec4-a01b-49f3-f8be-4c23514b05f6"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DP8iACDGDSWD",
        "colab": {}
      },
      "source": [
        "class DatasetClass(Dataset):\n",
        "    \n",
        "    def __init__(self, directory, img_size):\n",
        "        \n",
        "        self.directory = directory\n",
        "        self.classes = ['026.Bronzed_Cowbird',\t'084.Red_legged_Kittiwake',\t'131.Vesper_Sparrow',\t'085.Horned_Lark',\t'015.Lazuli_Bunting',\t'041.Scissor_tailed_Flycatcher',\t'114.Black_throated_Sparrow']\n",
        "        print('Number of Classes =', len(self.classes))\n",
        "        self.files = []\n",
        "        for class_name in self.classes:\n",
        "            images = os.listdir(directory + '/' + class_name)\n",
        "            images = [class_name + '/' + image for image in images]\n",
        "            self.files.extend(images)\n",
        "        \n",
        "        self.img_size = img_size\n",
        "        self.size = len(self.files)\n",
        "        \n",
        "    def __getitem__(self, idx):     \n",
        "        \n",
        "        image_name = self.files[idx]\n",
        "        y = self.classes.index(re.split('/', image_name)[0])\n",
        "        img = Image.open(self.directory + '/' + image_name).convert(mode='RGB').resize(self.img_size)\n",
        "        \n",
        "        trans = transforms.ToTensor()\n",
        "        # return trans(img), torch.Tensor(y, dtype=torch.long)\n",
        "        \n",
        "        return trans(img)*255, y        # Multiplying by pixel value\n",
        "      \n",
        "    def __len__(self):\n",
        "        \n",
        "        return self.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TKVGwDDOKAsM",
        "colab": {}
      },
      "source": [
        "def train_test_loader(directory, img_size, train_fraction=0.7, cv_fraction=0.2, num_workers=0, batch_size=32):\n",
        "\n",
        "    dataset = DatasetClass(directory, img_size)\n",
        "    \n",
        "    N = dataset.size\n",
        "    train_size = int(N*train_fraction)\n",
        "    cv_size = int(N*cv_fraction)\n",
        "    test_size = N - train_size - cv_size\n",
        "\n",
        "    train_data, cv_data, test_data = torch.utils.data.random_split(dataset, [train_size, cv_size, test_size])\n",
        "\n",
        "    trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    cvloader = DataLoader(cv_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    testloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    \n",
        "    return trainloader, cvloader, testloader, train_size, cv_size, test_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fT66UkOpUDtv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d399c1c9-7f26-4419-c251-a168f5c9447b"
      },
      "source": [
        "# trainloader, cvloader, testloader, train_size, cv_size, test_size = train_test_loader('D:/_SEM8/DL/Assignment 3/Assignment3_Data/CUB_200_2011/images/', (224, 224))\n",
        "trainloader, cvloader, testloader, train_size, cv_size, test_size = train_test_loader('/content/drive/My Drive/Assignment3_Data/CUB_200_2011/images', (224, 224), batch_size=32)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "  # trainloader, cvloader, testloader, train_size, cv_size, test_size = train_test_loader('Assignment3_Data/CUB_200_2011/images/', (224, 224))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Classes = 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "81_AjruYX-U6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42d71bd7-4b9d-413c-d425-af567da00b81"
      },
      "source": [
        "RGB_mean = torch.zeros(3)\n",
        "i = 0\n",
        "for X, y in trainloader:\n",
        "    i += 1\n",
        "    RGB_mean += (X.sum(0).sum(1).sum(1)/(X.shape[2]*X.shape[2]))/train_size\n",
        "    print(i, '/', len(trainloader), end=', ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 / 18, 2 / 18, 3 / 18, 4 / 18, 5 / 18, 6 / 18, 7 / 18, 8 / 18, 9 / 18, 10 / 18, 11 / 18, 12 / 18, 13 / 18, 14 / 18, 15 / 18, 16 / 18, 17 / 18, 18 / 18, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vc8N6oxxiwx0"
      },
      "source": [
        "### Question 1. a\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xzGC9uLa9xum",
        "colab": {}
      },
      "source": [
        "class VGGNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, RGB_mean, num_classes):\n",
        "        super(VGGNet, self).__init__()\n",
        "        \n",
        "        self.RGB_mean = RGB_mean.to(device)\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.c11 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n",
        "        self.c12 = nn.Conv2d(64, 64, 3, stride=1, padding=1)\n",
        "        self.p1 = nn.MaxPool2d(2, stride=2)\n",
        "\n",
        "        self.c21 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n",
        "        self.c22 = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n",
        "        self.p2 = nn.MaxPool2d(2, stride=2)\n",
        "\n",
        "        self.c31 = nn.Conv2d(128, 256, 3, stride=1, padding=1)\n",
        "        self.c32 = nn.Conv2d(256, 256, 3, stride=1, padding=1)\n",
        "        self.c33 = nn.Conv2d(256, 256, 3, stride=1, padding=1)\n",
        "        self.p3 = nn.MaxPool2d(2, stride=2)\n",
        "\n",
        "        self.c41 = nn.Conv2d(256, 512, 3, stride=1, padding=1)\n",
        "        self.c42 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
        "        self.c43 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
        "        self.p4 = nn.MaxPool2d(2, stride=2)\n",
        "\n",
        "        self.c51 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
        "        self.c52 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
        "        self.c53 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
        "        self.p5 = nn.MaxPool2d(2, stride=2)\n",
        "\n",
        "        self.flat = nn.Flatten(1, -1)\n",
        "        self.fc1 = nn.Linear(7*7*512, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.out = nn.Linear(4096, self.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x - self.RGB_mean[None, :, None, None]\n",
        "        x = self.p1(F.relu(self.c12(F.relu(self.c11(x)))))\n",
        "        x = self.p1(F.relu(self.c22(F.relu(self.c21(x)))))\n",
        "        x = self.p3(F.relu(self.c33(F.relu(self.c32(F.relu(self.c31(x)))))))\n",
        "        x = self.p4(F.relu(self.c43(F.relu(self.c42(F.relu(self.c41(x)))))))\n",
        "        x = self.p5(F.relu(self.c53(F.relu(self.c52(F.relu(self.c51(x)))))))\n",
        "        x = F.relu(self.fc2(F.relu(self.fc1(self.flat(x)))))\n",
        "        Z = self.out(x)\n",
        "\n",
        "\n",
        "        return Z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EwuOkncsWXVy",
        "colab": {}
      },
      "source": [
        "VGG_model = VGGNet(RGB_mean, 7)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(VGG_model.parameters(), lr=0.001, momentum=0.9)\n",
        "VGG_model = VGG_model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VUTJaWtqSqQj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b0e2334f-8805-468f-ff86-1339c80d37d2"
      },
      "source": [
        "old_loss = np.inf\n",
        "\n",
        "max_epoch = 100\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for data in trainloader:\n",
        "        \n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward\n",
        "        y_hat = VGG_model(X)\n",
        "        \n",
        "        # Calculate Loss (Cross Entropy)\n",
        "        loss = criterion(y_hat, y)\n",
        "        \n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update Parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()*len(X)/train_size\n",
        "    \n",
        "    print('Epoch', epoch+1, ': Loss =', running_loss)\n",
        "    \n",
        "    # if abs(running_loss-old_loss)/running_loss < 1e-5:\n",
        "    #     print('Converged')\n",
        "    #     break\n",
        "    \n",
        "    old_loss = running_loss\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 : Loss = 1.9530172580625953\n",
            "Epoch 2 : Loss = 1.9529275395728989\n",
            "Epoch 3 : Loss = 1.9527151393558089\n",
            "Epoch 4 : Loss = 1.9525855858566867\n",
            "Epoch 5 : Loss = 1.952393295872918\n",
            "Epoch 6 : Loss = 1.9523229831602515\n",
            "Epoch 7 : Loss = 1.9523652771208762\n",
            "Epoch 8 : Loss = 1.9521083898245248\n",
            "Epoch 9 : Loss = 1.9520235892372264\n",
            "Epoch 10 : Loss = 1.9520390407548962\n",
            "Epoch 11 : Loss = 1.9518214900319169\n",
            "Epoch 12 : Loss = 1.9517714935728065\n",
            "Epoch 13 : Loss = 1.951701592900612\n",
            "Epoch 14 : Loss = 1.9516678055819734\n",
            "Epoch 15 : Loss = 1.9515274526350175\n",
            "Epoch 16 : Loss = 1.951506910423784\n",
            "Epoch 17 : Loss = 1.9514779147370769\n",
            "Epoch 18 : Loss = 1.9514151383775455\n",
            "Epoch 19 : Loss = 1.9514355144434272\n",
            "Epoch 20 : Loss = 1.9514344644048074\n",
            "Epoch 21 : Loss = 1.9512953608708932\n",
            "Epoch 22 : Loss = 1.951222456290747\n",
            "Epoch 23 : Loss = 1.9512854851912123\n",
            "Epoch 24 : Loss = 1.951167887511569\n",
            "Epoch 25 : Loss = 1.9512696548621409\n",
            "Epoch 26 : Loss = 1.9511845485673962\n",
            "Epoch 27 : Loss = 1.9511680137820362\n",
            "Epoch 28 : Loss = 1.951142912542363\n",
            "Epoch 29 : Loss = 1.9510807409519106\n",
            "Epoch 30 : Loss = 1.9509946444308714\n",
            "Epoch 31 : Loss = 1.9511103281160678\n",
            "Epoch 32 : Loss = 1.9508805557410478\n",
            "Epoch 33 : Loss = 1.9509624321701637\n",
            "Epoch 34 : Loss = 1.95097251387008\n",
            "Epoch 35 : Loss = 1.95102566044505\n",
            "Epoch 36 : Loss = 1.9510068527912845\n",
            "Epoch 37 : Loss = 1.9509663199713831\n",
            "Epoch 38 : Loss = 1.9509248368000733\n",
            "Epoch 39 : Loss = 1.950917619446013\n",
            "Epoch 40 : Loss = 1.950979066642735\n",
            "Epoch 41 : Loss = 1.9509179783199722\n",
            "Epoch 42 : Loss = 1.9509118708168591\n",
            "Epoch 43 : Loss = 1.9507642606409588\n",
            "Epoch 44 : Loss = 1.950861774670538\n",
            "Epoch 45 : Loss = 1.9509549024628432\n",
            "Epoch 46 : Loss = 1.950817181258252\n",
            "Epoch 47 : Loss = 1.9508722285360411\n",
            "Epoch 48 : Loss = 1.9507669455498355\n",
            "Epoch 49 : Loss = 1.9508375307408776\n",
            "Epoch 50 : Loss = 1.9507534013807981\n",
            "Epoch 51 : Loss = 1.9509724607035672\n",
            "Epoch 52 : Loss = 1.9508190221487436\n",
            "Epoch 53 : Loss = 1.950853573735998\n",
            "Epoch 54 : Loss = 1.9507967985465555\n",
            "Epoch 55 : Loss = 1.950891036189807\n",
            "Epoch 56 : Loss = 1.9508090866567365\n",
            "Epoch 57 : Loss = 1.9508230760953151\n",
            "Epoch 58 : Loss = 1.9507540194415047\n",
            "Epoch 59 : Loss = 1.9507393920047773\n",
            "Epoch 60 : Loss = 1.9508225045553067\n",
            "Epoch 61 : Loss = 1.9508592359695702\n",
            "Epoch 62 : Loss = 1.9509423019994012\n",
            "Epoch 63 : Loss = 1.9507758310032222\n",
            "Epoch 64 : Loss = 1.9507960409237532\n",
            "Epoch 65 : Loss = 1.9507220464301027\n",
            "Epoch 66 : Loss = 1.9508635491028898\n",
            "Epoch 67 : Loss = 1.9507539330459225\n",
            "Epoch 68 : Loss = 1.9507676034854264\n",
            "Epoch 69 : Loss = 1.9507797653251406\n",
            "Epoch 70 : Loss = 1.9508820444033952\n",
            "Epoch 71 : Loss = 1.9508952429901014\n",
            "Epoch 72 : Loss = 1.9508314697584621\n",
            "Epoch 73 : Loss = 1.950775259463214\n",
            "Epoch 74 : Loss = 1.95070289983982\n",
            "Epoch 75 : Loss = 1.9507590104478578\n",
            "Epoch 76 : Loss = 1.9508154865756677\n",
            "Epoch 77 : Loss = 1.9507332047518955\n",
            "Epoch 78 : Loss = 1.9507321945881593\n",
            "Epoch 79 : Loss = 1.9507446488436917\n",
            "Epoch 80 : Loss = 1.9507225780952266\n",
            "Epoch 81 : Loss = 1.950818550295946\n",
            "Epoch 82 : Loss = 1.9508218532655297\n",
            "Epoch 83 : Loss = 1.9506570570144917\n",
            "Epoch 84 : Loss = 1.9507752528173996\n",
            "Epoch 85 : Loss = 1.9506747814005676\n",
            "Epoch 86 : Loss = 1.9507750135680941\n",
            "Epoch 87 : Loss = 1.9507125030411248\n",
            "Epoch 88 : Loss = 1.9507165171128116\n",
            "Epoch 89 : Loss = 1.9507752528174\n",
            "Epoch 90 : Loss = 1.9507528298407897\n",
            "Epoch 91 : Loss = 1.9507267583122652\n",
            "Epoch 92 : Loss = 1.9506600742140712\n",
            "Epoch 93 : Loss = 1.9507398638575748\n",
            "Epoch 94 : Loss = 1.9506447689043103\n",
            "Epoch 95 : Loss = 1.9508226707006577\n",
            "Epoch 96 : Loss = 1.9506962872548388\n",
            "Epoch 97 : Loss = 1.950694645738768\n",
            "Epoch 98 : Loss = 1.9506049338948854\n",
            "Epoch 99 : Loss = 1.9507468087332591\n",
            "Epoch 100 : Loss = 1.9507919138732275\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuguuhIInaRW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "6d7a8db1-1724-4001-b3ec-47ea2fe5732c"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    train_loss = 0.0\n",
        "    y_train = []\n",
        "    y_train_pred = []\n",
        "\n",
        "    for data in trainloader:\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        y_hat = VGG_model(X)\n",
        "        train_loss += criterion(y_hat, y)*len(X)/train_size\n",
        "        \n",
        "        y_train.extend(list(y.detach().cpu().numpy()))\n",
        "        y_train_pred.extend(list(torch.argmax(y_hat, axis=1).detach().cpu().numpy()))\n",
        "\n",
        "print('Train Loss =', test_loss.item())\n",
        "plt.imshow(confusion_matrix(y_train, y_train_pred), cmap='Reds')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Loss = 2.2523725032806396\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ok3viz8oX4nv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "40e90eeb-7579-497c-be8f-f0359666f1c9"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    test_loss = 0.0\n",
        "    y_test = []\n",
        "    y_test_pred = []\n",
        "\n",
        "    for data in testloader:\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        y_hat = VGG_model(X)      \n",
        "        test_loss += criterion(y_hat, y)*len(X)/test_size\n",
        "        \n",
        "        y_test.extend(list(y.detach().cpu().numpy()))\n",
        "        y_test_pred.extend(list(torch.argmax(y_hat, axis=1).detach().cpu().numpy()))\n",
        "\n",
        "print('Test Loss =', test_loss.item())\n",
        "plt.imshow(confusion_matrix(y_test, y_test_pred), cmap='Reds')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss = 2.253988027572632\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r_MY7HHT7GYv"
      },
      "source": [
        "### Question 1. b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZEvZrYhn7JuX",
        "colab": {}
      },
      "source": [
        "class GoogLeNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_classes, RGB_mean):\n",
        "    \n",
        "        super(GoogLeNet, self).__init__()\n",
        "        self.RGB_mean = RGB_mean.to(device)\n",
        "        self.n_classes = n_classes\n",
        "        # Convolution\n",
        "        # 3x224x224\n",
        "        self.c1 = nn.Conv2d(3, 64, 7, stride=2, padding=3)\n",
        "        # 64x112x112\n",
        "        self.mp1 = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        # Deep Convolution\n",
        "        # 64x56x56\n",
        "        self.c21 = nn.Conv2d(64, 64, 1, stride=1, padding=0)\n",
        "        # 64x56x56\n",
        "        self.c22 = nn.Conv2d(64, 192, 3, stride=1, padding=1)\n",
        "        # 192x56x56\n",
        "        self.mp2 = nn.MaxPool2d(3, stride=2)\n",
        "\n",
        "        # Inception 3a\n",
        "        # 192x28x28\n",
        "        # P1\n",
        "        self.c3a1 = nn.Conv2d(192, 64, 1, stride=1, padding=0)\n",
        "        # P2\n",
        "        self.c3a21 = nn.Conv2d(192, 96, 1, stride=1, padding=0)\n",
        "        self.c3a22 = nn.Conv2d(96, 128, 3, stride=1, padding=1)\n",
        "        # P3\n",
        "        self.c3a31 = nn.Conv2d(192, 16, 1, stride=1, padding=0)\n",
        "        self.c3a32 = nn.Conv2d(16, 32, 5, stride=1, padding=2)\n",
        "        # P4\n",
        "        self.mp3a4 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.c3a4 = nn.Conv2d(192, 32, 1, stride=1, padding=0)\n",
        "\n",
        "        # Inception 3b\n",
        "        # 256x28x28\n",
        "        # P1\n",
        "        self.c3b1 = nn.Conv2d(256, 128, 1, stride=1, padding=0)\n",
        "        # P2\n",
        "        self.c3b21 = nn.Conv2d(256, 128, 1, stride=1, padding=0)\n",
        "        self.c3b22 = nn.Conv2d(128, 192, 3, stride=1, padding=1)\n",
        "        # P3\n",
        "        self.c3b31 = nn.Conv2d(256, 32, 1, stride=1, padding=0)\n",
        "        self.c3b32 = nn.Conv2d(32, 96, 5, stride=1, padding=2)\n",
        "        # P4\n",
        "        self.mp3b4 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.c3b4 = nn.Conv2d(256, 64, 1, stride=1, padding=0)\n",
        "\n",
        "        # 480x28x28\n",
        "        # MP\n",
        "        self.mp3 = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        # Inception 4a\n",
        "        # 480x14x14\n",
        "        # P1\n",
        "        self.c4a1 = nn.Conv2d(480, 192, 1, stride=1, padding=0)\n",
        "        # P2\n",
        "        self.c4a21 = nn.Conv2d(480, 96, 1, stride=1, padding=0)\n",
        "        self.c4a22 = nn.Conv2d(96, 208, 3, stride=1, padding=1)\n",
        "        # P3\n",
        "        self.c4a31 = nn.Conv2d(480, 16, 1, stride=1, padding=0)\n",
        "        self.c4a32 = nn.Conv2d(16, 48, 5, stride=1, padding=2)\n",
        "        # P4\n",
        "        self.mp4a4 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.c4a4 = nn.Conv2d(480, 64, 1, stride=1, padding=0)\n",
        "\n",
        "        # Auxiliary 1\n",
        "        # 512x14x14\n",
        "        self.apa1 = nn.AvgPool2d(5, stride=3, padding=0)\n",
        "        # 512x4x4\n",
        "        self.ca1 = nn.Conv2d(512, 128, 1, stride=1)\n",
        "        # 128x4x4\n",
        "        self.flat1 = nn.Flatten(1, -1)\n",
        "        # (128x4x4)x1\n",
        "        self.fca1 = nn.Linear(2048, 1024)\n",
        "        self.a1drop = nn.Dropout(0.7)\n",
        "        self.a1out = nn.Linear(1024, self.n_classes)\n",
        "\n",
        "        # Inception 4b\n",
        "        # 512x14x14\n",
        "        # P1\n",
        "        self.c4b1 = nn.Conv2d(512, 160, 1, stride=1, padding=0)\n",
        "        # P2\n",
        "        self.c4b21 = nn.Conv2d(512, 112, 1, stride=1, padding=0)\n",
        "        self.c4b22 = nn.Conv2d(112, 224, 3, stride=1, padding=1)\n",
        "        # P3\n",
        "        self.c4b31 = nn.Conv2d(512, 24, 1, stride=1, padding=0)\n",
        "        self.c4b32 = nn.Conv2d(24, 64, 5, stride=1, padding=2)\n",
        "        # P4\n",
        "        self.mp4b4 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.c4b4 = nn.Conv2d(512, 64, 1, stride=1, padding=0)\n",
        "\n",
        "        # Inception 4c\n",
        "        # 512x14x14\n",
        "        # P1\n",
        "        self.c4c1 = nn.Conv2d(512, 128, 1, stride=1, padding=0)\n",
        "        # P2\n",
        "        self.c4c21 = nn.Conv2d(512, 128, 1, stride=1, padding=0)\n",
        "        self.c4c22 = nn.Conv2d(128, 256, 3, stride=1, padding=1)\n",
        "        # P3\n",
        "        self.c4c31 = nn.Conv2d(512, 24, 1, stride=1, padding=0)\n",
        "        self.c4c32 = nn.Conv2d(24, 64, 5, stride=1, padding=2)\n",
        "        # P4\n",
        "        self.mp4c4 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.c4c4 = nn.Conv2d(512, 64, 1, stride=1, padding=0)\n",
        "\n",
        "        # Inception 4d\n",
        "        # 512x14x14\n",
        "        # P1\n",
        "        self.c4d1 = nn.Conv2d(512, 112, 1, stride=1, padding=0)\n",
        "        # P2\n",
        "        self.c4d21 = nn.Conv2d(512, 144, 1, stride=1, padding=0)\n",
        "        self.c4d22 = nn.Conv2d(144, 288, 3, stride=1, padding=1)\n",
        "        # P3\n",
        "        self.c4d31 = nn.Conv2d(512, 32, 1, stride=1, padding=0)\n",
        "        self.c4d32 = nn.Conv2d(32, 64, 5, stride=1, padding=2)\n",
        "        # P4\n",
        "        self.mp4d4 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.c4d4 = nn.Conv2d(512, 64, 1, stride=1, padding=0)\n",
        "\n",
        "        # Auxiliary 2\n",
        "        # 528x14x14\n",
        "        self.apa2 = nn.AvgPool2d(5, stride=3, padding=0)\n",
        "        # 528x4x4\n",
        "        self.ca2 = nn.Conv2d(528, 128, 1, stride=1)\n",
        "        # 128x4x4\n",
        "        self.flat1 = nn.Flatten(1, -1)\n",
        "        # (128x4x4)x1\n",
        "        self.fca2 = nn.Linear(2048, 1024)\n",
        "        self.a2drop = nn.Dropout(0.7)\n",
        "        self.a2out = nn.Linear(1024, self.n_classes)\n",
        "\n",
        "        # Inception 4e\n",
        "        # 528x14x14\n",
        "        # P1\n",
        "        self.c4e1 = nn.Conv2d(528, 256, 1, stride=1, padding=0)\n",
        "        # P2\n",
        "        self.c4e21 = nn.Conv2d(528, 160, 1, stride=1, padding=0)\n",
        "        self.c4e22 = nn.Conv2d(160, 320, 3, stride=1, padding=1)\n",
        "        # P3\n",
        "        self.c4e31 = nn.Conv2d(528, 32, 1, stride=1, padding=0)\n",
        "        self.c4e32 = nn.Conv2d(32, 128, 5, stride=1, padding=2)\n",
        "        # P4\n",
        "        self.mp4e4 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.c4e4 = nn.Conv2d(528, 128, 1, stride=1, padding=0)\n",
        "\n",
        "        # 832x14x14\n",
        "        # MP\n",
        "        self.mp4 = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        # Inception 5a\n",
        "        # 832x7x7\n",
        "        # P1\n",
        "        self.c5a1 = nn.Conv2d(832, 256, 1, stride=1, padding=0)\n",
        "        # P2\n",
        "        self.c5a21 = nn.Conv2d(832, 160, 1, stride=1, padding=0)\n",
        "        self.c5a22 = nn.Conv2d(160, 320, 3, stride=1, padding=1)\n",
        "        # P3\n",
        "        self.c5a31 = nn.Conv2d(832, 32, 1, stride=1, padding=0)\n",
        "        self.c5a32 = nn.Conv2d(32, 128, 5, stride=1, padding=2)\n",
        "        # P4\n",
        "        self.mp5a4 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.c5a4 = nn.Conv2d(832, 128, 1, stride=1, padding=0)\n",
        "\n",
        "        # Inception 5b\n",
        "        # 832x7x7\n",
        "        # P1\n",
        "        self.c5b1 = nn.Conv2d(832, 384, 1, stride=1, padding=0)\n",
        "        # P2\n",
        "        self.c5b21 = nn.Conv2d(832, 192, 1, stride=1, padding=0)\n",
        "        self.c5b22 = nn.Conv2d(192, 384, 3, stride=1, padding=1)\n",
        "        # P3\n",
        "        self.c5b31 = nn.Conv2d(832, 48, 1, stride=1, padding=0)\n",
        "        self.c5b32 = nn.Conv2d(48, 128, 5, stride=1, padding=2)\n",
        "        # P4\n",
        "        self.mp5b4 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.c5b4 = nn.Conv2d(832, 128, 1, stride=1, padding=0)\n",
        "\n",
        "        # 1024x7x7\n",
        "        self.ap = nn.AvgPool2d(7, stride=1)\n",
        "        # 1024x1x1\n",
        "        self.drop = nn.Dropout(0.4)\n",
        "        self.flat = nn.Flatten(1, -1)\n",
        "        self.out = nn.Linear(1024, self.n_classes)\n",
        "\n",
        "    def forward(self, x, auxiliary=True):\n",
        "\n",
        "        x = x - self.RGB_mean[None, :, None, None]\n",
        "\n",
        "        # Layer 1\n",
        "        x = self.mp1(F.relu(self.c1(x)))\n",
        "\n",
        "        # Layer 2\n",
        "        x = self.mp2(F.relu(self.c22(F.relu(self.c21(x)))))\n",
        "\n",
        "        # Layer 3a\n",
        "        x1 = F.relu(self.c3a1(x))\n",
        "        x2 = F.relu(self.c3a22(F.relu(self.c3a21(x))))\n",
        "        x3 = F.relu(self.c3a32(F.relu(self.c3a31(x))))\n",
        "        x4 = F.relu(self.c3a4(self.mp3a4(x)))\n",
        "        x = torch.cat((x1, x2, x3, x4), 1)\n",
        "\n",
        "        # Layer 3b\n",
        "        x1 = F.relu(self.c3b1(x))\n",
        "        x2 = F.relu(self.c3b22(F.relu(self.c3b21(x))))\n",
        "        x3 = F.relu(self.c3b32(F.relu(self.c3b31(x))))\n",
        "        x4 = F.relu(self.c3b4(self.mp3b4(x)))\n",
        "        x = self.mp3(torch.cat((x1, x2, x3, x4), 1))\n",
        "\n",
        "        # Layer 4a\n",
        "        x1 = F.relu(self.c4a1(x))\n",
        "        x2 = F.relu(self.c4a22(F.relu(self.c4a21(x))))\n",
        "        x3 = F.relu(self.c4a32(F.relu(self.c4a31(x))))\n",
        "        x4 = F.relu(self.c4a4(self.mp4a4(x)))\n",
        "        x = torch.cat((x1, x2, x3, x4), 1)\n",
        "\n",
        "        # Auxiliary 1\n",
        "        if auxiliary == True:\n",
        "            z1 = self.flat1(F.relu(self.ca1(self.apa1(x))))\n",
        "            z1 = self.a1out(self.a1drop(F.relu(self.fca1(z1))))\n",
        "        else:\n",
        "            z1 = None\n",
        "\n",
        "        # Layer 4b\n",
        "        x1 = F.relu(self.c4b1(x))\n",
        "        x2 = F.relu(self.c4b22(F.relu(self.c4b21(x))))\n",
        "        x3 = F.relu(self.c4b32(F.relu(self.c4b31(x))))\n",
        "        x4 = F.relu(self.c4b4(self.mp4b4(x)))\n",
        "        x = torch.cat((x1, x2, x3, x4), 1)\n",
        "\n",
        "        # Layer 4c\n",
        "        x1 = F.relu(self.c4c1(x))\n",
        "        x2 = F.relu(self.c4c22(F.relu(self.c4c21(x))))\n",
        "        x3 = F.relu(self.c4c32(F.relu(self.c4c31(x))))\n",
        "        x4 = F.relu(self.c4c4(self.mp4c4(x)))\n",
        "        x = torch.cat((x1, x2, x3, x4), 1)\n",
        "\n",
        "        # Layer 4d\n",
        "        x1 = F.relu(self.c4d1(x))\n",
        "        x2 = F.relu(self.c4d22(F.relu(self.c4d21(x))))\n",
        "        x3 = F.relu(self.c4d32(F.relu(self.c4d31(x))))\n",
        "        x4 = F.relu(self.c4d4(self.mp4d4(x)))\n",
        "        x = torch.cat((x1, x2, x3, x4), 1)\n",
        "\n",
        "        # Auxiliary 2\n",
        "        if auxiliary == True:\n",
        "            z2 = self.flat(F.relu(self.ca2(self.apa2(x))))\n",
        "            z2 = self.a2out(self.a2drop(F.relu(self.fca2(z2))))\n",
        "        else:\n",
        "            z2 = None\n",
        "\n",
        "        # Layer 4e\n",
        "        x1 = F.relu(self.c4e1(x))\n",
        "        x2 = F.relu(self.c4e22(F.relu(self.c4e21(x))))\n",
        "        x3 = F.relu(self.c4e32(F.relu(self.c4e31(x))))\n",
        "        x4 = F.relu(self.c4e4(self.mp4e4(x)))\n",
        "        x = self.mp4(torch.cat((x1, x2, x3, x4), 1))\n",
        "\n",
        "        # Layer 5a\n",
        "        x1 = F.relu(self.c5a1(x))\n",
        "        x2 = F.relu(self.c5a22(F.relu(self.c5a21(x))))\n",
        "        x3 = F.relu(self.c5a32(F.relu(self.c5a31(x))))\n",
        "        x4 = F.relu(self.c5a4(self.mp5a4(x)))\n",
        "        x = torch.cat((x1, x2, x3, x4), 1)\n",
        "\n",
        "        # Layer 5b\n",
        "        x1 = F.relu(self.c5b1(x))\n",
        "        x2 = F.relu(self.c5b22(F.relu(self.c5b21(x))))\n",
        "        x3 = F.relu(self.c5b32(F.relu(self.c5b31(x))))\n",
        "        x4 = F.relu(self.c5b4(self.mp5b4(x)))\n",
        "        x = torch.cat((x1, x2, x3, x4), 1)\n",
        "\n",
        "        # Final Output\n",
        "        x = self.out(self.flat(self.drop(self.ap(x))))\n",
        "\n",
        "        return x, z1, z2\n",
        "\n",
        "    \n",
        "    def predict(self, x):\n",
        "\n",
        "        y_hat = self.forward(x)\n",
        "        y_hat = torch.argmax(y_hat, axis=1)\n",
        "        return y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k-5ltA0Q2kdX",
        "colab": {}
      },
      "source": [
        "classifier = GoogLeNet(7, RGB_mean)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(classifier.parameters(), lr=0.001, momentum=0.9)\n",
        "classifier = classifier.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QOH2pEviO6nE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "84bed4da-93a4-40c1-c9ad-d5ca28d150b6"
      },
      "source": [
        "\n",
        "old_loss = np.inf\n",
        "\n",
        "max_epoch = 100\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for data in trainloader:\n",
        "        \n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward\n",
        "        y_hat, y_hat1, y_hat2 = classifier(X)\n",
        "        \n",
        "        # Calculate Loss (Cross Entropy)\n",
        "        loss_main = criterion(y_hat, y)\n",
        "        loss1 = criterion(y_hat1, y)\n",
        "        loss2 = criterion(y_hat2, y)\n",
        "\n",
        "        # Weighted Loss\n",
        "        loss = loss_main + 0.3*loss1 + 0.3*loss2\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update Parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()*len(X)16/train_size\n",
        "    \n",
        "    print('Epoch', epoch+1, ': Loss =', running_loss)\n",
        "    \n",
        "    # if abs(running_loss-old_loss)/running_loss < 1e-5:\n",
        "    #     print('Converged')\n",
        "    #     break\n",
        "    \n",
        "    old_loss = running_loss\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 : Loss = 3.1238052952995696\n",
            "Epoch 2 : Loss = 3.1230392854803535\n",
            "Epoch 3 : Loss = 3.1222557041287837\n",
            "Epoch 4 : Loss = 3.1212302284373643\n",
            "Epoch 5 : Loss = 3.122042758954942\n",
            "Epoch 6 : Loss = 3.12227149458297\n",
            "Epoch 7 : Loss = 3.121719347059934\n",
            "Epoch 8 : Loss = 3.120970004942359\n",
            "Epoch 9 : Loss = 3.120733320920725\n",
            "Epoch 10 : Loss = 3.120026963928435\n",
            "Epoch 11 : Loss = 3.1203691568939527\n",
            "Epoch 12 : Loss = 3.1206211528711614\n",
            "Epoch 13 : Loss = 3.119851793561663\n",
            "Epoch 14 : Loss = 3.119395412219111\n",
            "Epoch 15 : Loss = 3.120387937964462\n",
            "Epoch 16 : Loss = 3.1187823491644777\n",
            "Epoch 17 : Loss = 3.1189311622327214\n",
            "Epoch 18 : Loss = 3.1190011027798\n",
            "Epoch 19 : Loss = 3.1165639232675377\n",
            "Epoch 20 : Loss = 3.117623810984117\n",
            "Epoch 21 : Loss = 3.1180430555177487\n",
            "Epoch 22 : Loss = 3.1181528709491366\n",
            "Epoch 23 : Loss = 3.115429894849398\n",
            "Epoch 24 : Loss = 3.1176778414523563\n",
            "Epoch 25 : Loss = 3.115609398286933\n",
            "Epoch 26 : Loss = 3.1165187848984988\n",
            "Epoch 27 : Loss = 3.1164356989312254\n",
            "Epoch 28 : Loss = 3.115076231208828\n",
            "Epoch 29 : Loss = 3.1142714497104342\n",
            "Epoch 30 : Loss = 3.113716045738513\n",
            "Epoch 31 : Loss = 3.114166525598187\n",
            "Epoch 32 : Loss = 3.1118426173406197\n",
            "Epoch 33 : Loss = 3.1126616075894558\n",
            "Epoch 34 : Loss = 3.1127608030099903\n",
            "Epoch 35 : Loss = 3.111731366413395\n",
            "Epoch 36 : Loss = 3.1118661568139907\n",
            "Epoch 37 : Loss = 3.11004764942342\n",
            "Epoch 38 : Loss = 3.109134793696919\n",
            "Epoch 39 : Loss = 3.109476415122428\n",
            "Epoch 40 : Loss = 3.1040607811266536\n",
            "Epoch 41 : Loss = 3.1036466272865852\n",
            "Epoch 42 : Loss = 3.1002469079419708\n",
            "Epoch 43 : Loss = 3.100230120615677\n",
            "Epoch 44 : Loss = 3.0974772383527065\n",
            "Epoch 45 : Loss = 3.0927302795835487\n",
            "Epoch 46 : Loss = 3.093684671647872\n",
            "Epoch 47 : Loss = 3.0822818370646305\n",
            "Epoch 48 : Loss = 3.085298637895219\n",
            "Epoch 49 : Loss = 3.0820934415278947\n",
            "Epoch 50 : Loss = 3.0788125759217797\n",
            "Epoch 51 : Loss = 3.0683816251854448\n",
            "Epoch 52 : Loss = 3.066642016899295\n",
            "Epoch 53 : Loss = 3.0607128076852415\n",
            "Epoch 54 : Loss = 3.0553530649856406\n",
            "Epoch 55 : Loss = 3.049960571714394\n",
            "Epoch 56 : Loss = 3.0451587583960555\n",
            "Epoch 57 : Loss = 3.0332160843374005\n",
            "Epoch 58 : Loss = 3.0346160915255136\n",
            "Epoch 59 : Loss = 3.02311949779763\n",
            "Epoch 60 : Loss = 3.017672070227434\n",
            "Epoch 61 : Loss = 3.0050598171114506\n",
            "Epoch 62 : Loss = 3.020624074371019\n",
            "Epoch 63 : Loss = 3.012790480557219\n",
            "Epoch 64 : Loss = 2.987224180108579\n",
            "Epoch 65 : Loss = 2.9898432954263185\n",
            "Epoch 66 : Loss = 2.978492271609423\n",
            "Epoch 67 : Loss = 2.977321943754934\n",
            "Epoch 68 : Loss = 2.9800978737010353\n",
            "Epoch 69 : Loss = 2.989417750660966\n",
            "Epoch 70 : Loss = 2.96784091909588\n",
            "Epoch 71 : Loss = 2.964165943424876\n",
            "Epoch 72 : Loss = 2.9631611495067847\n",
            "Epoch 73 : Loss = 2.9890824826336906\n",
            "Epoch 74 : Loss = 2.9443509304565003\n",
            "Epoch 75 : Loss = 2.961014963608586\n",
            "Epoch 76 : Loss = 2.9508424685807184\n",
            "Epoch 77 : Loss = 2.9380501537788204\n",
            "Epoch 78 : Loss = 2.9470148119776924\n",
            "Epoch 79 : Loss = 2.9399164844473065\n",
            "Epoch 80 : Loss = 2.9221484087900826\n",
            "Epoch 81 : Loss = 2.92536402579384\n",
            "Epoch 82 : Loss = 2.923080391169425\n",
            "Epoch 83 : Loss = 2.9206154454460536\n",
            "Epoch 84 : Loss = 2.925782911453513\n",
            "Epoch 85 : Loss = 2.8978091382814197\n",
            "Epoch 86 : Loss = 2.9133586817086776\n",
            "Epoch 87 : Loss = 2.9131306638285674\n",
            "Epoch 88 : Loss = 2.8979167871774276\n",
            "Epoch 89 : Loss = 2.8985227525026542\n",
            "Epoch 90 : Loss = 2.889909578117344\n",
            "Epoch 91 : Loss = 2.885534691893681\n",
            "Epoch 92 : Loss = 2.8777792395615\n",
            "Epoch 93 : Loss = 2.8764389782417115\n",
            "Epoch 94 : Loss = 2.874917179865289\n",
            "Epoch 95 : Loss = 2.8878813687101887\n",
            "Epoch 96 : Loss = 2.85564547548726\n",
            "Epoch 97 : Loss = 2.8542298373444983\n",
            "Epoch 98 : Loss = 2.8737023383482825\n",
            "Epoch 99 : Loss = 2.865447413215238\n",
            "Epoch 100 : Loss = 2.8672596868322286\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVvSW-o33fn7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a4db908d-e4e5-44e2-98b8-733f5d84fe86"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    train_loss = 0.0\n",
        "    y_train = []\n",
        "    y_train_pred = []\n",
        "\n",
        "    for data in trainloader:\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        y_hat, _, _ = classifier(X)      \n",
        "        train_loss += criterion(y_hat, y)*len(X)/train_size\n",
        "        \n",
        "        y_train.extend(list(y.detach().cpu().numpy()))\n",
        "        y_train_pred.extend(list(torch.argmax(y_hat, axis=1).detach().cpu().numpy()))\n",
        "\n",
        "print('Train Loss =', train_loss.item())\n",
        "plt.imshow(confusion_matrix(y_train, y_train_pred), cmap='Reds')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Loss = 1.9430598020553589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylNoy_9_3fA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "974ac671-600c-42f4-f0a3-7444558e016b"
      },
      "source": [
        "acc = accuracy_score(y_train, y_train_pred)\n",
        "prec = precision_score(y_train, y_train_pred, average='macro')\n",
        "f1 = f1_score(y_train, y_train_pred, average='macro')\n",
        "\n",
        "print('Train Accuracy =', acc, 'Train Precision =', prec, 'Train F1 =', f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy = 0.1602787456445993 Train Precision = 0.022896963663514184 Train F1 = 0.039468039468039465\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ATw2OTqQiJCq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "b56155dd-17f5-4b85-8a7d-09cb2129279e"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    test_loss = 0.0\n",
        "    y_test = []\n",
        "    y_test_pred = []\n",
        "\n",
        "    for data in testloader:\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        y_hat, _, _ = classifier(X)      \n",
        "        test_loss += criterion(y_hat, y)*len(X)/test_size\n",
        "        \n",
        "        y_test.extend(list(y.detach().cpu().numpy()))\n",
        "        y_test_pred.extend(list(torch.argmax(y_hat, axis=1).detach().cpu().numpy()))\n",
        "\n",
        "print('Test Loss =', test_loss.item())\n",
        "plt.imshow(confusion_matrix(y_test, y_test_pred), cmap='Reds')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss = 1.9689445495605469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgq5cyyZ4m15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "4196425a-ff6c-48f3-a247-51016ad3e4ec"
      },
      "source": [
        "acc = accuracy_score(y_test, y_test_pred)\n",
        "prec = precision_score(y_test, y_test_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "\n",
        "print('Train Accuracy =', acc, 'Train Precision =', prec, 'Train F1 =', f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy = 0.047619047619047616 Train Precision = 0.006802721088435374 Train F1 = 0.012987012987012986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s1RPoXsreDy4"
      },
      "source": [
        "### Question 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NuqwHPPlQavd",
        "colab": {}
      },
      "source": [
        "class CNN2(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_classes):\n",
        "        super(CNN2, self).__init__()\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        # 3x224x224\n",
        "        self.cl1 = nn.Conv2d(3, 4, 3, stride=1, padding=1)\n",
        "        # 4x224x224\n",
        "        self.pl1 = nn.AvgPool2d(2, stride=2)\n",
        "        # 4x112x112\n",
        "        self.cl2 = nn.Conv2d(4, 16, 3, stride=1, padding=1)\n",
        "        # 16x112x112\n",
        "        self.pl2 = nn.AvgPool2d(2, stride=2)\n",
        "\n",
        "        # 16x56x56\n",
        "        self.flat = nn.Flatten(1, -1)\n",
        "        # (16x56x56)x1\n",
        "        self.out = nn.Linear(16*56*56, self.n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.pl1(F.relu(self.cl1(x)))\n",
        "        x = self.pl2(F.relu(self.cl2(x)))\n",
        "        x = self.out(self.flat(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "\n",
        "        y_hat = self.forward(x)\n",
        "        y_hat = torch.argmax(y_hat, axis=1)\n",
        "        return y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y4dEykLIhv7s",
        "colab": {}
      },
      "source": [
        "classifier = CNN2(7)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(classifier.parameters(), lr=0.0001, momentum=0.9)\n",
        "classifier = classifier.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_3RX6TtEhMFp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "4ce92e13-ce65-4301-930e-5cccd21edd7e"
      },
      "source": [
        "old_loss = np.inf\n",
        "from IPython.display import clear_output\n",
        "losses = []\n",
        "max_epoch = 200\n",
        "for epoch in range(max_epoch):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for data in trainloader:\n",
        "            \n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward\n",
        "        y_hat = classifier(X)\n",
        "        \n",
        "        # Calculate Loss (Cross Entropy)\n",
        "        loss = criterion(y_hat, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update Parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()*len(X)/train_size\n",
        "\n",
        "    print('Epoch', epoch+1, ': Loss =', running_loss)\n",
        "    losses.append(running_loss)\n",
        "\n",
        "    \n",
        "    if (abs(running_loss-old_loss)/running_loss < 0.2) and epoch>=10 and running_loss<0.01:\n",
        "        print('Converged')\n",
        "        break\n",
        "    \n",
        "    old_loss = running_loss\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 : Loss = 8.51608510382915\n",
            "Epoch 2 : Loss = 1.9994171861987495\n",
            "Epoch 3 : Loss = 1.9447825997548651\n",
            "Epoch 4 : Loss = 1.9335377008657422\n",
            "Epoch 5 : Loss = 1.924046891906951\n",
            "Epoch 6 : Loss = 1.915209303749563\n",
            "Epoch 7 : Loss = 1.8966690609264043\n",
            "Epoch 8 : Loss = 1.880748568926954\n",
            "Epoch 9 : Loss = 1.8649288818811292\n",
            "Epoch 10 : Loss = 1.8444972038269043\n",
            "Epoch 11 : Loss = 1.8139404183065437\n",
            "Epoch 12 : Loss = 1.783672104729177\n",
            "Epoch 13 : Loss = 1.748245834888897\n",
            "Epoch 14 : Loss = 1.6984773778749263\n",
            "Epoch 15 : Loss = 1.6479445400969077\n",
            "Epoch 16 : Loss = 1.5252120798057796\n",
            "Epoch 17 : Loss = 1.3692599933737246\n",
            "Epoch 18 : Loss = 1.1686137353917032\n",
            "Epoch 19 : Loss = 0.993157974103602\n",
            "Epoch 20 : Loss = 0.7433030617777064\n",
            "Epoch 21 : Loss = 0.5656542364728576\n",
            "Epoch 22 : Loss = 0.4901453439366943\n",
            "Epoch 23 : Loss = 0.36426011267854774\n",
            "Epoch 24 : Loss = 0.3462182510812939\n",
            "Epoch 25 : Loss = 0.3036954419538119\n",
            "Epoch 26 : Loss = 0.10046271201002474\n",
            "Epoch 27 : Loss = 0.06260648136147225\n",
            "Epoch 28 : Loss = 0.04024827143482422\n",
            "Epoch 29 : Loss = 0.026623422656377016\n",
            "Epoch 30 : Loss = 0.01634821658532171\n",
            "Epoch 31 : Loss = 0.01191775640635021\n",
            "Epoch 32 : Loss = 0.009365431529563895\n",
            "Epoch 33 : Loss = 0.008167996201080104\n",
            "Converged\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RskMmPeG5RAU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "f000db14-7758-4968-c0c9-89cbcd23fcb1"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    train_loss = 0.0\n",
        "    y_train = []\n",
        "    y_train_pred = []\n",
        "\n",
        "    for data in trainloader:\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        y_hat = classifier(X)      \n",
        "        train_loss += criterion(y_hat, y)*len(X)/train_size\n",
        "        \n",
        "        y_train.extend(list(y.detach().cpu().numpy()))\n",
        "        y_train_pred.extend(list(torch.argmax(y_hat, axis=1).detach().cpu().numpy()))\n",
        "\n",
        "print('Train Loss =', train_loss.item())\n",
        "plt.imshow(confusion_matrix(y_train, y_train_pred), cmap='Reds')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Loss = 0.007632026448845863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s1_WEeod6Bg2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1f2c8f9-6acb-401c-d029-0dca544e1bac"
      },
      "source": [
        "acc_tr = accuracy_score(y_train, y_train_pred)\n",
        "prec_tr = precision_score(y_train, y_train_pred, average='weighted')\n",
        "f1_tr = f1_score(y_train, y_train_pred, average='weighted')\n",
        "\n",
        "print('Train Accuracy =', acc_tr, 'Train Precision =', prec_tr, 'Train F1 =', f1_tr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy = 1.0 Train Precision = 1.0 Train F1 = 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Uf2CJP5jrId",
        "colab_type": "code",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5864ba77-5740-4bc4-b682-aa2e6f9ae5f5"
      },
      "source": [
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4eAKVd07iASJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a81f39e0-6cd6-43c7-949e-9b39eea22f4b"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    test_loss = 0.0\n",
        "    y_test = []\n",
        "    y_test_pred = []\n",
        "\n",
        "    for data in testloader:\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        y_hat = classifier(X)      \n",
        "        test_loss += criterion(y_hat, y)*len(X)/test_size\n",
        "        \n",
        "        y_test.extend(list(y.detach().cpu().numpy()))\n",
        "        y_test_pred.extend(list(torch.argmax(y_hat, axis=1).detach().cpu().numpy()))\n",
        "\n",
        "print('Test Loss =', test_loss.item())\n",
        "plt.imshow(confusion_matrix(y_test, y_test_pred), cmap='Reds')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss = 3.1113786697387695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qJK9h5xu4DjA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1934143c-b626-4505-c384-52d9bf3af7f2"
      },
      "source": [
        "acc = accuracy_score(y_test, y_test_pred)\n",
        "prec = precision_score(y_test, y_test_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "\n",
        "print('Test Accuracy =', acc, 'Test Precision =', prec, 'Test F1 =', f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy = 0.2619047619047619 Test Precision = 0.28922902494331065 Test F1 = 0.25354090354090353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_vIZ1K6eE33v"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jVC5hAh8E33x",
        "colab": {}
      },
      "source": [
        "class CNN3(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_classes, k=4):\n",
        "        super(CNN3, self).__init__()\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        # 3x224x224\n",
        "        self.cl1 = nn.Conv2d(3, 4, 3, stride=1, padding=1)\n",
        "        # 4x224x224\n",
        "        self.pl1 = nn.AvgPool2d(2, stride=2)\n",
        "        # 4x112x112\n",
        "        self.cl2 = nn.Conv2d(4, 16, 3, stride=1, padding=1)\n",
        "        # 16x112x112\n",
        "        self.pl2 = nn.AvgPool2d(2, stride=2)\n",
        "\n",
        "        # NetVLAD\n",
        "        self.K = k\n",
        "        self.nv_conv = nn.Conv2d(16, self.K, 1)\n",
        "        self.nv_soft_ass = nn.Softmax2d()\n",
        "\n",
        "        # NetVLAD Parameter\n",
        "        self.c = nn.Parameter(torch.rand(self.K, 16))\n",
        "        \n",
        "        # Flatten to get h\n",
        "        self.flat = nn.Flatten(1, -1)\n",
        "\n",
        "        # Output layer\n",
        "        self.out = nn.Linear(self.K*16, self.n_classes)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        # print(x.shape)\n",
        "        x = self.pl1(F.relu(self.cl1(x)))\n",
        "        # print(x.shape)\n",
        "        x = self.pl2(F.relu(self.cl2(x)))\n",
        "        # print(x.shape)\n",
        "        \n",
        "        # NetVLAD Step 1\n",
        "        a = self.nv_soft_ass(self.nv_conv(x))\n",
        "\n",
        "        # NetVLAD Step 2\n",
        "        for k in range(self.K):\n",
        "            a_k = a[:, k, :, :]\n",
        "            c_k = self.c[k, :]\n",
        "            temp = (x - c_k.reshape(1, -1, 1, 1))*a_k.unsqueeze(1)\n",
        "            z_k = torch.sum(temp, axis=(2, 3))\n",
        "            if k==0:\n",
        "                Z = z_k.unsqueeze(1)\n",
        "            else:\n",
        "                Z = torch.cat((Z, z_k.unsqueeze(1)), 1)\n",
        "        \n",
        "        # Flatten\n",
        "        Z = self.flat(Z)\n",
        "        # print('Z shape', Z.shape)\n",
        "        Z = self.out(Z)\n",
        "\n",
        "        return Z\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "\n",
        "        y_hat = self.forward(x)\n",
        "        y_hat = torch.argmax(y_hat, axis=1)\n",
        "        return y_hat"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2NO7TpyJE330",
        "colab": {}
      },
      "source": [
        "classifier = CNN3(7)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(classifier.parameters(), lr=0.0001, momentum=0.9)\n",
        "classifier = classifier.to(device)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tmxv4-HM1did",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e3a390f0-8156-403e-daa8-91280233a4fd"
      },
      "source": [
        "old_loss = np.inf\n",
        "from IPython.display import clear_output\n",
        "losses = []\n",
        "max_epoch = 200\n",
        "for epoch in range(max_epoch):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for data in trainloader:\n",
        "            \n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward\n",
        "        y_hat = classifier(X)\n",
        "        \n",
        "        # Calculate Loss (Cross Entropy)\n",
        "        loss = criterion(y_hat, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update Parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()*len(X)/train_size\n",
        "\n",
        "    print('Epoch', epoch+1, ': Loss =', running_loss)\n",
        "    losses.append(running_loss)\n",
        "\n",
        "    \n",
        "    if (abs(running_loss-old_loss)/running_loss < 0.2) and epoch>=10 and running_loss<0.01:\n",
        "        print('Converged')\n",
        "        break\n",
        "    \n",
        "    old_loss = running_loss\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 : Loss = 85807623.2677891\n",
            "Epoch 2 : Loss = 28301.72832507622\n",
            "Epoch 3 : Loss = 18408.02954186629\n",
            "Epoch 4 : Loss = 43676.23143510452\n",
            "Epoch 5 : Loss = 43213.82771668119\n",
            "Epoch 6 : Loss = 126600.11846689894\n",
            "Epoch 7 : Loss = 240719.85224303138\n",
            "Epoch 8 : Loss = 215393.4227324695\n",
            "Epoch 9 : Loss = 71398.49858449477\n",
            "Epoch 10 : Loss = 141169.75748584495\n",
            "Epoch 11 : Loss = 207208.68343042248\n",
            "Epoch 12 : Loss = 56377.06017258275\n",
            "Epoch 13 : Loss = 39714.29333623694\n",
            "Epoch 14 : Loss = 69156.5947027439\n",
            "Epoch 15 : Loss = 49089.8818121189\n",
            "Epoch 16 : Loss = 115871.9918336237\n",
            "Epoch 17 : Loss = 96327.01796602787\n",
            "Epoch 18 : Loss = 180568.33177264806\n",
            "Epoch 19 : Loss = 158264.56037674216\n",
            "Epoch 20 : Loss = 189712.8424978223\n",
            "Epoch 21 : Loss = 186683.625\n",
            "Epoch 22 : Loss = 348658.04322735185\n",
            "Epoch 23 : Loss = 444821.3343858886\n",
            "Epoch 24 : Loss = 376555.8679224739\n",
            "Epoch 25 : Loss = 439843.20198170736\n",
            "Epoch 26 : Loss = 271717.7355182927\n",
            "Epoch 27 : Loss = 346034.916104094\n",
            "Epoch 28 : Loss = 582051.9578614983\n",
            "Epoch 29 : Loss = 458804.6652874565\n",
            "Epoch 30 : Loss = 782716.6406794424\n",
            "Epoch 31 : Loss = 737370.8886106273\n",
            "Epoch 32 : Loss = 1109940.2602351916\n",
            "Epoch 33 : Loss = 1259644.2229965155\n",
            "Epoch 34 : Loss = 1218806.8020470385\n",
            "Epoch 35 : Loss = 1253718.5966898955\n",
            "Epoch 36 : Loss = 1410611.5966898955\n",
            "Epoch 37 : Loss = 1033366.2402003484\n",
            "Epoch 38 : Loss = 890387.5984320558\n",
            "Epoch 39 : Loss = 919064.6055095819\n",
            "Epoch 40 : Loss = 1764849.037456446\n",
            "Epoch 41 : Loss = 2898772.5217770035\n",
            "Epoch 42 : Loss = 1614562.4259581878\n",
            "Epoch 43 : Loss = 1797812.1681184666\n",
            "Epoch 44 : Loss = 2174955.413763066\n",
            "Epoch 45 : Loss = 1540044.131533101\n",
            "Epoch 46 : Loss = 1730273.8837108014\n",
            "Epoch 47 : Loss = 1958297.656794425\n",
            "Epoch 48 : Loss = 1609277.43793554\n",
            "Epoch 49 : Loss = 2174077.093858885\n",
            "Epoch 50 : Loss = 2493788.206010453\n",
            "Epoch 51 : Loss = 2400234.141768293\n",
            "Epoch 52 : Loss = 2040736.8732578398\n",
            "Epoch 53 : Loss = 2971595.155923345\n",
            "Epoch 54 : Loss = 4200028.503484321\n",
            "Epoch 55 : Loss = 8876385.809233451\n",
            "Epoch 56 : Loss = 11815059.135888502\n",
            "Epoch 57 : Loss = 5941518.754355401\n",
            "Epoch 58 : Loss = 11030383.993031358\n",
            "Epoch 59 : Loss = 16088955.707317073\n",
            "Epoch 60 : Loss = 16107798.655052265\n",
            "Epoch 61 : Loss = 25727843.770034846\n",
            "Epoch 62 : Loss = 29940467.972125437\n",
            "Epoch 63 : Loss = 47400227.72125436\n",
            "Epoch 64 : Loss = 66212622.773519166\n",
            "Epoch 65 : Loss = 53510676.153310105\n",
            "Epoch 66 : Loss = 33647129.31010453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAJMMT7Z0_Ri",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "522c15f7-3340-4a72-f00c-8e2ce384dd52"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    train_loss = 0.0\n",
        "    y_train = []\n",
        "    y_train_pred = []\n",
        "\n",
        "    for data in trainloader:\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        y_hat = classifier(X)      \n",
        "        train_loss += criterion(y_hat, y)*len(X)/train_size\n",
        "        \n",
        "        y_train.extend(list(y.detach().cpu().numpy()))\n",
        "        y_train_pred.extend(list(torch.argmax(y_hat, axis=1).detach().cpu().numpy()))\n",
        "\n",
        "print('Train Loss =', train_loss.item())\n",
        "plt.imshow(confusion_matrix(y_train, y_train_pred), cmap='Reds')\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Loss = 21922.796875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsXfxUyu1OJm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c3a72c9d-8c46-4da8-87f9-5b876309617a"
      },
      "source": [
        "acc_tr = accuracy_score(y_train, y_train_pred)\n",
        "prec_tr = precision_score(y_train, y_train_pred, average='weighted')\n",
        "f1_tr = f1_score(y_train, y_train_pred, average='weighted')\n",
        "\n",
        "print('Train Accuracy =', acc_tr, 'Train Precision =', prec_tr, 'Train F1 =', f1_tr)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy = 0.13240418118466898 Train Precision = 0.017530867195182653 Train F1 = 0.030962208523184133\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lcw20TIlE334",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "20e16188-c826-4eed-af1b-6afda2df8118"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    test_loss = 0.0\n",
        "    y_test = []\n",
        "    y_test_pred = []\n",
        "\n",
        "    for data in testloader:\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        y_hat = classifier(X)      \n",
        "        test_loss += criterion(y_hat, y)\n",
        "        \n",
        "        y_test.extend(list(y.detach().cpu().numpy()))\n",
        "        y_test_pred.extend(list(torch.argmax(y_hat, axis=1).detach().cpu().numpy()))\n",
        "\n",
        "print('Test Loss =', test_loss.item())\n",
        "plt.imshow(confusion_matrix(y_test, y_test_pred), cmap='Reds')\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss = 57528.66796875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FckLra-d1Ulv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = accuracy_score(y_test, y_test_pred)\n",
        "prec = precision_score(y_test, y_test_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "\n",
        "print('Test Accuracy =', acc, 'Test Precision =', prec, 'Test F1 =', f1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}